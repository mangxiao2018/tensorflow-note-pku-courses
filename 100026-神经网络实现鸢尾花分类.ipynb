{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络实现鸢尾花分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step1、数据集读入</strong> </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从sklearn包datasets读入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需模块\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回iris数据集所有输入特征\n",
    "x_data = datasets.load_iris().data\n",
    "# 返回iris数据集所有标签\n",
    "y_data = datasets.load_iris().target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step2、数据集乱序</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机打乱数据（因为原始数据是顺序的，顺序不打乱会影响准确率）\n",
    "# seed: 随机数种子，是一个整数，当设置之后，每次生成的随机数都一样（为方便教学，以保每位同学结果一致）\n",
    "np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n",
    "np.random.shuffle(x_data)\n",
    "np.random.seed(116)\n",
    "np.random.shuffle(y_data)\n",
    "tf.random.set_seed(116)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step3、数据集分出永不想见的训练集和测试集</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将打乱后的数据集分割为训练集和测试集，训练集为前120行，测试集为后30行\n",
    "x_train = x_data[:-30]\n",
    "y_train = y_data[:-30]\n",
    "\n",
    "x_test = x_data[-30:]\n",
    "y_test = y_data[-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step4、配成[输入特征,标签]对，每次喂入一小撮(batch)</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换x的数据类型，否则后面矩阵相乘时会因数据类型不一致报错\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_tensor_slices函数使输入特征和标签值一一对应。（把数据集分批次，每个批次batch组数据）\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step5、定义神经网络中所有可训练参数</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成神经网络的参数，4个输入特征故，输入层为4个输入节点；因为3分类，故输出层为3个神经元\n",
    "# 用tf.Variable()标记参数可训练\n",
    "# 使用seed使每次生成的随机数相同（方便教学，使大家结果都一致，在现实使用时不写seed）\n",
    "w1 = tf.Variable(tf.random.truncated_normal([4, 3], stddev=0.1, seed=1))\n",
    "b1 = tf.Variable(tf.random.truncated_normal([3], stddev=0.1, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step6、嵌套循环跌代，with结构参数，显示当前loss</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1  # 学习率为0.1\n",
    "train_loss_results = []  # 将每轮的loss记录在此列表中，为后续画loss曲线提供数据\n",
    "test_acc = []  # 将每轮的acc记录在此列表中，为后续画acc曲线提供数据\n",
    "epoch = 500  # 循环500轮\n",
    "loss_all = 0  # 每轮分4个step，loss_all记录四个step生成的4个loss的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.2821310982108116\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.25459614023566246\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.22570250183343887\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.21028400212526321\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.19942265003919601\n",
      "Test_acc: 0.16666666666666666\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.18873638287186623\n",
      "Test_acc: 0.5\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.17851299419999123\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.16922875493764877\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.16107673197984695\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.15404684096574783\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.14802725985646248\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.14287303388118744\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.1384414155036211\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.13460607267916203\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.1312607266008854\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.12831821851432323\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.12570794858038425\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.12337299063801765\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.12126746959984303\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.11935433000326157\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.11760355532169342\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.11599067784845829\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.11449568346142769\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.11310208030045033\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.11179621517658234\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.11056671850383282\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.1094040796160698\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.10830028168857098\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.10724855586886406\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.10624313727021217\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.1052791029214859\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.10435222089290619\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.10345886647701263\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.10259587690234184\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.10176053084433079\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.10095042362809181\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.10016347281634808\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.09939785301685333\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.098651934415102\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.09792428836226463\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.09721364639699459\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.09651889279484749\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.09583901055157185\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.09517310746014118\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.09452036395668983\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.0938800685107708\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.09325156174600124\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.09263424947857857\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.09202760085463524\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.09143111668527126\n",
      "Test_acc: 0.5333333333333333\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.09084436297416687\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.09026693738996983\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.08969846740365028\n",
      "Test_acc: 0.5666666666666667\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.08913861028850079\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.08858705312013626\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.08804351277649403\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.08750772476196289\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.08697944693267345\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.08645843341946602\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.08594449236989021\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.08543741516768932\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.08493702113628387\n",
      "Test_acc: 0.6\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.08444313704967499\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.08395560085773468\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.08347426354885101\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.08299897983670235\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.08252961002290249\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.08206603676080704\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.0816081278026104\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.08115577697753906\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.08070887438952923\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.08026730641722679\n",
      "Test_acc: 0.6333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.07983098179101944\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.07939981482923031\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.07897369377315044\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.07855254411697388\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.07813627645373344\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.07772481068968773\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.07731806486845016\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.07691597566008568\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.07651845179498196\n",
      "Test_acc: 0.7\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.07612544111907482\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.07573685608804226\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.07535265013575554\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.07497275061905384\n",
      "Test_acc: 0.7333333333333333\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.07459708210080862\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.07422559335827827\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.07385822758078575\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.07349492330104113\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.0731356181204319\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.0727802598848939\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.07242879830300808\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.07208118122071028\n",
      "Test_acc: 0.7666666666666667\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.07173734251409769\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.07139723561704159\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.07106082048267126\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.07072803843766451\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.07039883732795715\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.07007318176329136\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.0697510102763772\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.06943229492753744\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.06911696959286928\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.06880500260740519\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.068496348336339\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.06819095741957426\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.06788879353553057\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.06758981756865978\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.0672939782962203\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.06700124125927687\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.06671155989170074\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.06642490718513727\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.06614123564213514\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.06586050800979137\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.06558268237859011\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.06530772428959608\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.06503560300916433\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.06476627010852098\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.06449970323592424\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.06423585396260023\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.06397469528019428\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.06371619179844856\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.06346031185239553\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.06320700887590647\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.06295627169311047\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.06270804442465305\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.062462314032018185\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.062219033017754555\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.061978185549378395\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.06173973437398672\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.06150364130735397\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.06126988586038351\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.06103843078017235\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.060809263959527016\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.06058233231306076\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.06035762373358011\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.06013510562479496\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.05991474352777004\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.05969652719795704\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.05948041472584009\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.059266386553645134\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.059054408222436905\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.058844465762376785\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.05863652750849724\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.058430563658475876\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.058226559311151505\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.05802448187023401\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.05782431084662676\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.0576260257512331\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.05742959305644035\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.057234992273151875\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.05704221595078707\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.05685121938586235\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.05666199326515198\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.05647451523691416\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.0562887629494071\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.05610471125692129\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.05592234432697296\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.0557416332885623\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.05556256324052811\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.05538512021303177\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.05520927160978317\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.0550350034609437\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.054862307384610176\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.05469114426523447\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.05452151037752628\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.05435337871313095\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.05418673437088728\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.054021554067730904\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.053857832215726376\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.05369554739445448\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.05353467632085085\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.05337520316243172\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.05321711581200361\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.053060390055179596\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.05290501844137907\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.05275098513811827\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.0525982566177845\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.05244683939963579\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.05229670740664005\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.05214785039424896\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.052000246942043304\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.05185388680547476\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.05170875135809183\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.0515648303553462\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.0514221116900444\n",
      "Test_acc: 0.9666666666666667\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.05128058046102524\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.05114021524786949\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.051001012325286865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.0508629409596324\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.05072600767016411\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.05059019848704338\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.05045548640191555\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.050321875140070915\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.05018933489918709\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.05005786381661892\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.04992745537310839\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.04979807883501053\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.04966974165290594\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.04954242426902056\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.04941611457616091\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.049290805123746395\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.049166472628712654\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.04904312454164028\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.04892073106020689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.04879929404705763\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.04867880046367645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.04855923913419247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.048440598882734776\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.04832286946475506\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.04820604622364044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.04809010960161686\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.04797505959868431\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.04786087851971388\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.047747560776770115\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.04763508960604668\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.04752346687018871\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.0474126823246479\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.04730272572487593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.04719358030706644\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.04708524979650974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.046977708116173744\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.046870965510606766\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.04676500242203474\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.046659816056489944\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.046555391512811184\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.04645173158496618\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.046348825097084045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.04624664504081011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.046145214699208736\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.04604450333863497\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.04594451282173395\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.045845234766602516\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.04574666079133749\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.04564878437668085\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.04555159714072943\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.04545509163290262\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.045359269715845585\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.04526410344988108\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.04516960680484772\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.04507576581090689\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.044982570223510265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.04489001724869013\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.04479810781776905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.04470681864768267\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.04461614973843098\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.04452611040323973\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.04443667363375425\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.044347839429974556\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.04425961058586836\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.04417197220027447\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.044084908440709114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.043998440727591515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.04391253925859928\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.043827205896377563\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.04374244436621666\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.04365824069827795\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.04357459116727114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.043491488322615623\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.043408920988440514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.043326896615326405\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.04324540589004755\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.043164435774087906\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.04308399651199579\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.043004062958061695\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.04292465187609196\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.04284573998302221\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.04276733938604593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.042689427733421326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.042612009681761265\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.042535084299743176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.04245864413678646\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.0423826826736331\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.042307195253670216\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.04223217722028494\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.0421576201915741\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.042083533480763435\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.04200989939272404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.041936714202165604\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.041863986290991306\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.04179169982671738\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.041719854809343815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.041648441925644875\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.04157746955752373\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.04150692094117403\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.04143680352717638\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.04136709962040186\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.04129782039672136\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.04122895374894142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.04116049408912659\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.04109244793653488\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.04102479945868254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.04095755238085985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.040890694595873356\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.040824233554303646\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.040758166462183\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.040692479349672794\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.04062717128545046\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.040562248788774014\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.04049769788980484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.04043351951986551\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.04036970995366573\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.040306271985173225\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.04024319350719452\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.04018046986311674\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.040118103846907616\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.04005609406158328\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.03999443957582116\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.03993312222883105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.039872155059129\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.03981153108179569\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.03975124144926667\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.03969129454344511\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.03963167825713754\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.039572385139763355\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.0395134249702096\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.039454787503927946\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.039396482054144144\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.03933848813176155\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.03928081039339304\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.039223446510732174\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.039166401606053114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.039109662640839815\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.03905322263017297\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.03899709461256862\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.03894126648083329\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.038885737769305706\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.03883049916476011\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.03877555998042226\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.03872091369703412\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.038666556123644114\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.0386124849319458\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.038558701518923044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.03850520169362426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.03845197660848498\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.03839903511106968\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.03834636742249131\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.03829397866502404\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.038241852074861526\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.03819000208750367\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.03813841659575701\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.038087102584540844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.03803604608401656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.037985255010426044\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.0379347144626081\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.03788443887606263\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.037834418937563896\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.03778465045616031\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.03773513110354543\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.03768586413934827\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.03763684118166566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.037588071543723345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.037539539858698845\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.03749124659225345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.03744320431724191\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.03739539487287402\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.037347821053117514\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.037300472147762775\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.03725337469950318\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.03720649937167764\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.037159846629947424\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.03711343090981245\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.03706724522635341\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.03702127141878009\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.036975531373173\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.036930006463080645\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.036884702276438475\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.03683961182832718\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.036794747691601515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.03675009263679385\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.03670565178617835\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.03666142327710986\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.036617396865040064\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.03657358651980758\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.03652997827157378\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.03648658422753215\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.03644339134916663\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.03640039125457406\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.03635760257020593\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.0363150117918849\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.03627262031659484\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.036230423022061586\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.03618842549622059\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.03614661982282996\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.036105002742260695\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.03606357332319021\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.036022343672811985\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.03598130075260997\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.0359404431656003\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.035899775102734566\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.03585928911343217\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.035818991251289845\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.03577886475250125\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.035738930106163025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.035699169617146254\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.03565958747640252\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.0356201883405447\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.03558096336200833\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.035541911609470844\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.035503033082932234\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.03546432685106993\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.03542578825727105\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.03538742894306779\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.03534923028200865\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.03531120624393225\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.03527334099635482\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.035235646180808544\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.035198114812374115\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.03516074409708381\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.03512354753911495\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.035086496733129025\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.03504961961880326\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.03501288779079914\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.03497632406651974\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.034939910750836134\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.034903660882264376\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.03486755723133683\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.034831615164875984\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.03479582257568836\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.034760179463773966\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.03472469002008438\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.034689351450651884\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.03465416468679905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 422, loss: 0.03461912088096142\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.034584226086735725\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.0345494719222188\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.03451487235724926\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.034480408765375614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.03444609651342034\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.03441191930323839\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.034377888310700655\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.0343439974822104\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.03431024495512247\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.034276632592082024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.03424314921721816\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.034209814853966236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.034176611341536045\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.03414354659616947\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.034110613632947206\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.03407781524583697\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.03404514491558075\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.03401261428371072\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.03398020705208182\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.03394793579354882\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.03391578933224082\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.033883774653077126\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.03385189222171903\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.03382013039663434\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.033788496162742376\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.033756992779672146\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.03372560581192374\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.03369434829801321\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.03366321278735995\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.03363220160827041\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.03360130963847041\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.033570545725524426\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.03353988938033581\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.03350936621427536\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.03347895201295614\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.03344865795224905\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.033418478444218636\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.033388426061719656\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.033358484506607056\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.033328657038509846\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.033298940397799015\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.033269339706748724\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.03323985496535897\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.03321048337966204\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.03318122075870633\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.0331520764157176\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.033123028464615345\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.033094107173383236\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.033065286464989185\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.0330365770496428\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.03300797566771507\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.03297947999089956\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.03295109001919627\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.03292280342429876\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.03289463231340051\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.0328665585257113\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.03283859835937619\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.03281073085963726\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.03278297046199441\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.032755312509834766\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.03272775420919061\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.03270029416307807\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.032672947738319635\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.032645690720528364\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.03261853428557515\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.03259148681536317\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.03256453387439251\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.032537673600018024\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.03251091670244932\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.03248425014317036\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.0324576823040843\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.032431211322546005\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.03240483347326517\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.03237855713814497\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.03235236741602421\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.03232627175748348\n",
      "Test_acc: 1.0\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.0323002771474421\n",
      "Test_acc: 1.0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# 训练部分\n",
    "for epoch in range(epoch):  #数据集级别的循环，每个epoch循环一次数据集\n",
    "    for step, (x_train, y_train) in enumerate(train_db):  #batch级别的循环 ，每个step循环一个batch\n",
    "        with tf.GradientTape() as tape:  # with结构记录梯度信息\n",
    "            y = tf.matmul(x_train, w1) + b1  # 神经网络乘加运算\n",
    "            y = tf.nn.softmax(y)  # 使输出y符合概率分布（此操作后与独热码同量级，可相减求loss）\n",
    "            y_ = tf.one_hot(y_train, depth=3)  # 将标签值转换为独热码格式，方便计算loss和accuracy\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))  # 采用均方误差损失函数mse = mean(sum(y-out)^2)\n",
    "            loss_all += loss.numpy()  # 将每个step计算出的loss累加，为后续求loss平均值提供数据，这样计算的loss更准确\n",
    "        # 计算loss对各个参数的梯度\n",
    "        grads = tape.gradient(loss, [w1, b1])\n",
    "\n",
    "        # 实现梯度更新 w1 = w1 - lr * w1_grad    b = b - lr * b_grad\n",
    "        w1.assign_sub(lr * grads[0])  # 参数w1自更新\n",
    "        b1.assign_sub(lr * grads[1])  # 参数b自更新\n",
    "\n",
    "    # 每个epoch，打印loss信息\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/4))\n",
    "    train_loss_results.append(loss_all / 4)  # 将4个step的loss求平均记录在此变量中\n",
    "    loss_all = 0  # loss_all归零，为记录下一个epoch的loss做准备\n",
    "\n",
    "    # 测试部分\n",
    "    # total_correct为预测对的样本个数, total_number为测试的总样本数，将这两个变量都初始化为0\n",
    "    total_correct, total_number = 0, 0\n",
    "    for x_test, y_test in test_db:\n",
    "        # 使用更新后的参数进行预测\n",
    "        y = tf.matmul(x_test, w1) + b1\n",
    "        y = tf.nn.softmax(y)\n",
    "        pred = tf.argmax(y, axis=1)  # 返回y中最大值的索引，即预测的分类\n",
    "        # 将pred转换为y_test的数据类型\n",
    "        pred = tf.cast(pred, dtype=y_test.dtype)\n",
    "        # 若分类正确，则correct=1，否则为0，将bool型的结果转换为int型\n",
    "        correct = tf.cast(tf.equal(pred, y_test), dtype=tf.int32)\n",
    "        # 将每个batch的correct数加起来\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        # 将所有batch中的correct数加起来\n",
    "        total_correct += int(correct)\n",
    "        # total_number为测试的总样本数，也就是x_test的行数，shape[0]返回变量的行数\n",
    "        total_number += x_test.shape[0]\n",
    "    # 总的准确率等于total_correct/total_number\n",
    "    acc = total_correct / total_number\n",
    "    test_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step7、计算当前参数前向传播后的准确率真，显示当前acc</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'><strong>Step8、acc/loss可视化</strong> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(test_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
