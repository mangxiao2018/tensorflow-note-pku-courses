{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK8MOo9XEnJ-"
   },
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import pandas as pd\n",
    "import sys,os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据、观察数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CS__iAo4El3Z"
   },
   "outputs": [],
   "source": [
    "# 加载全量样本\n",
    "# user_log = pd.read_csv('./data_format1/user_log_format1.csv', dtype={'time_stamp':'str'})\n",
    "# user_info = pd.read_csv('./data_format1/user_info_format1.csv')\n",
    "# train_data1 = pd.read_csv('./data_format1/train_format1.csv')\n",
    "# submission = pd.read_csv('./data_format1/test_format1.csv')\n",
    "# train_data = pd.read_csv('./data_format2/train_format2.csv')\n",
    "\n",
    "'''\n",
    "train_format1：数据集中只包含 label为0和1的数据。\n",
    "train_format2：数据集中同时包含 label为0、1和-1的数据。\n",
    "user_info_format1：用户信息数据集。\n",
    "user_log_format1：用户日志数据集。\n",
    "'''\n",
    "\n",
    "# 文件路径\n",
    "filePath = sys.path[0]\n",
    "\n",
    "# 导入数据\n",
    "df_train1 = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'train_format1.csv', encoding='ISO-8859-1')\n",
    "df_train2 = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'train_format2.csv', encoding='ISO-8859-1')\n",
    "df_test1 = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'test_format1.csv', encoding='ISO-8859-1')\n",
    "df_test2 = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'test_format2.csv', encoding='ISO-8859-1')\n",
    "df_user_info = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'user_info_format1.csv', encoding='ISO-8859-1')\n",
    "df_user_log = pd.read_csv(filePath + os.sep + 'datasets' + os.sep + 'user_log_format1.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train1 shape:  (260864, 3) Index(['user_id', 'merchant_id', 'label'], dtype='object')\n",
      "df_train2 shape:  (7030723, 6) Index(['user_id', 'age_range', 'gender', 'merchant_id', 'label',\n",
      "       'activity_log'],\n",
      "      dtype='object')\n",
      "df_test1 shape:  (261477, 3) Index(['user_id', 'merchant_id', 'prob'], dtype='object')\n",
      "df_test2 shape:  (7027943, 6) Index(['user_id', 'age_range', 'gender', 'merchant_id', 'label',\n",
      "       'activity_log'],\n",
      "      dtype='object')\n",
      "df_user_info shape:  (424170, 3) Index(['user_id', 'age_range', 'gender'], dtype='object')\n",
      "df_user_log shape:  (54925330, 7) Index(['user_id', 'item_id', 'cat_id', 'seller_id', 'brand_id', 'time_stamp',\n",
      "       'action_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 查看数据规模\n",
    "# print('----------数据集规模-------------')\n",
    "print('df_train1 shape: ', df_train1.shape, df_train1.columns)\n",
    "print('df_train2 shape: ', df_train2.shape, df_train2.columns)\n",
    "print('df_test1 shape: ', df_test1.shape, df_test1.columns)\n",
    "print('df_test2 shape: ', df_test2.shape, df_test2.columns)\n",
    "print('df_user_info shape: ', df_user_info.shape, df_user_info.columns)\n",
    "print('df_user_log shape: ', df_user_log.shape, df_user_log.columns)\n",
    "\n",
    "# 查看数据大体情况\n",
    "# print('-----------数据集字段-------------')\n",
    "# print('df_train1 head: \\n', df_train1.head())\n",
    "# print('df_train2 head: \\n', df_train2.head())\n",
    "# print('df_test1 head: \\n', df_test1.head())\n",
    "# print('df_test2 head: \\n', df_test2.head())\n",
    "# print('df_user_info head: \\n', df_user_info.head())\n",
    "# print('df_user_log head: \\n', df_user_log.head())\n",
    "\n",
    "# 查看是否有缺失值\n",
    "# print(df_train1.info(verbose=True,null_counts=True))\n",
    "# print(df_train2.info(verbose=True,null_counts=True))\n",
    "# print(df_test1.info(verbose=True,null_counts=True))\n",
    "# print(df_test2.info(verbose=True,null_counts=True))\n",
    "# print(df_user_info.info(verbose=True,null_counts=True))\n",
    "# print(df_user_log.info(verbose=True,null_counts=True))\n",
    "\n",
    "# 特殊值查看\n",
    "# print('df_train1 label: \\n', df_train1['label'].value_counts())\n",
    "# print('df_train2 label: \\n', df_train2['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ef_iyJIWQyUL"
   },
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1843,
     "status": "ok",
     "timestamp": 1591454889879,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "PvqmPMtYP1tn",
    "outputId": "7295a1fb-c581-495f-e77f-b79dc1afd34a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id  label origin  age_range  gender\n",
       "0         34176         3906    0.0  train        6.0     0.0\n",
       "1         34176          121    0.0  train        6.0     0.0\n",
       "2         34176         4356    1.0  train        6.0     0.0\n",
       "3         34176         2217    0.0  train        6.0     0.0\n",
       "4        230784         4818    0.0  train        0.0     0.0\n",
       "...         ...          ...    ...    ...        ...     ...\n",
       "522336   228479         3111    NaN   test        6.0     0.0\n",
       "522337    97919         2341    NaN   test        8.0     1.0\n",
       "522338    97919         3971    NaN   test        8.0     1.0\n",
       "522339    32639         3536    NaN   test        0.0     0.0\n",
       "522340    32639         3319    NaN   test        0.0     0.0\n",
       "\n",
       "[522341 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1['origin'] = 'train'\n",
    "df_test1['origin'] = 'test'\n",
    "matrix = pd.concat([df_train1, df_test1], ignore_index=True, sort=False)\n",
    "matrix.drop(['prob'], axis=1, inplace=True)\n",
    "# 连接user_info表，通过user_id关联\n",
    "matrix = matrix.merge(df_user_info, on='user_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9340,
     "status": "ok",
     "timestamp": 1591454901115,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "I91QWtqjsT9M",
    "outputId": "0805b96c-8bad-400a-e766-1ddb5073838a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender\n",
       "0         34176         3906   0.0  train          6       0\n",
       "1         34176          121   0.0  train          6       0\n",
       "2         34176         4356   1.0  train          6       0\n",
       "3         34176         2217   0.0  train          6       0\n",
       "4        230784         4818   0.0  train          0       0\n",
       "...         ...          ...   ...    ...        ...     ...\n",
       "522336   228479         3111   nan   test          6       0\n",
       "522337    97919         2341   nan   test          8       1\n",
       "522338    97919         3971   nan   test          8       1\n",
       "522339    32639         3536   nan   test          0       0\n",
       "522340    32639         3319   nan   test          0       0\n",
       "\n",
       "[522341 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 格式化\n",
    "df_user_log.rename(columns={'seller_id':'merchant_id'}, inplace=True)  # 使用merchant_id（原列名seller_id）\n",
    "df_user_log['user_id'] = df_user_log['user_id'].astype('int32')\n",
    "df_user_log['merchant_id'] = df_user_log['merchant_id'].astype('int32')\n",
    "df_user_log['item_id'] = df_user_log['item_id'].astype('int32')\n",
    "df_user_log['cat_id'] = df_user_log['cat_id'].astype('int32')\n",
    "df_user_log['brand_id'].fillna(0, inplace=True)\n",
    "df_user_log['brand_id'] = df_user_log['brand_id'].astype('int32')\n",
    "df_user_log['time_stamp'] = pd.to_datetime(df_user_log['time_stamp'], format='%H%M')\n",
    "\n",
    "matrix['age_range'].fillna(0, inplace=True)  # 0 and NULL for unknown\n",
    "matrix['gender'].fillna(2, inplace=True)  # 2 and NULL:unknown\n",
    "matrix['age_range'] = matrix['age_range'].astype('int8')\n",
    "matrix['gender'] = matrix['gender'].astype('int8')\n",
    "matrix['label'] = matrix['label'].astype('str')\n",
    "matrix['user_id'] = matrix['user_id'].astype('int32')\n",
    "matrix['merchant_id'] = matrix['merchant_id'].astype('int32')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GVaAPE1tMcL"
   },
   "source": [
    "### 特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 293983,
     "status": "ok",
     "timestamp": 1591455200167,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "RYp92CpBqxwE",
    "outputId": "282edd98-537a-459d-807b-4b2394156f32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zhangyanqing\\.conda\\envs\\tf2.0\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>u5</th>\n",
       "      <th>u6</th>\n",
       "      <th>u7</th>\n",
       "      <th>u8</th>\n",
       "      <th>u9</th>\n",
       "      <th>u10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>282</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4   u5        u6      u7   u8    u9    u10  \n",
       "0       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "1       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "2       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "3       109  108  5.833333   410.0  NaN  34.0    7.0  \n",
       "4        20   19  5.166667    47.0  NaN   7.0    NaN  \n",
       "...     ...  ...       ...     ...  ...   ...    ...  \n",
       "522336  278  282  6.000000  1770.0  NaN  26.0  208.0  \n",
       "522337   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
       "522338   17   17  4.750000    46.0  NaN   8.0    1.0  \n",
       "522339   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
       "522340   33   35  5.800000    62.0  1.0   8.0    1.0  \n",
       "\n",
       "[522341 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User特征处理\n",
    "groups = df_user_log.groupby(['user_id'])\n",
    "\n",
    "# 用户交互行为数量 u1\n",
    "temp = groups.size().reset_index().rename(columns={0:'u1'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 使用agg 基于列的聚合操作，统计唯一值的个数 item_id, cat_id, merchant_id, brand_id\n",
    "temp = groups['item_id', 'cat_id', 'merchant_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'u2', 'cat_id':'u3', 'merchant_id':'u4', 'brand_id':'u5'})\n",
    "temp = groups['item_id'].agg([('u2', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['cat_id'].agg([('u3', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['merchant_id'].agg([('u4', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "temp = groups['brand_id'].agg([('u5', 'nunique')]).reset_index()\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "\n",
    "# 时间间隔特征 u6 按照小时\n",
    "temp = groups['time_stamp'].agg([('F_time', 'min'), ('L_time', 'max')]).reset_index()\n",
    "temp['u6'] = (temp['L_time'] - temp['F_time']).dt.seconds/3600\n",
    "matrix = matrix.merge(temp[['user_id', 'u6']], on='user_id', how='left')\n",
    "\n",
    "# 统计操作类型为0，1，2，3的个数，0表示单击，1表示添加到购物车，2表示购买，3表示添加到收藏夹\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'u7', 1:'u8', 2:'u9', 3:'u10'})\n",
    "matrix = matrix.merge(temp, on='user_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 292602,
     "status": "ok",
     "timestamp": 1591455959081,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "tDMRmoowtUkD",
    "outputId": "85cf6bc9-490f-4e28-b17e-49f851e7e449"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zhangyanqing\\.conda\\envs\\tf2.0\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>...</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>m10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>16269</td>\n",
       "      <td>5819</td>\n",
       "      <td>308</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>14870.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>79865</td>\n",
       "      <td>10931</td>\n",
       "      <td>1179</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>72265.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4780.0</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>7269</td>\n",
       "      <td>2281</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>6094.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>60202</td>\n",
       "      <td>16870</td>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52230.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>48089</td>\n",
       "      <td>7500</td>\n",
       "      <td>461</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>43268.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>10105</td>\n",
       "      <td>4154</td>\n",
       "      <td>542</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>8997.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>5543</td>\n",
       "      <td>1592</td>\n",
       "      <td>352</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>28892</td>\n",
       "      <td>7587</td>\n",
       "      <td>272</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>24602.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2608.0</td>\n",
       "      <td>1588.0</td>\n",
       "      <td>3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>14027</td>\n",
       "      <td>4956</td>\n",
       "      <td>322</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>12807.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>2177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>25959</td>\n",
       "      <td>7927</td>\n",
       "      <td>952</td>\n",
       "      <td>175</td>\n",
       "      <td>85</td>\n",
       "      <td>21737.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4  ...     m1     m2    m3   m4  m5       m6     m7      m8      m9  \\\n",
       "0       109  ...  16269   5819   308   20   2  14870.0   28.0   410.0   961.0   \n",
       "1       109  ...  79865  10931  1179   26   2  72265.0  121.0  4780.0  2699.0   \n",
       "2       109  ...   7269   2281    67   15   2   6094.0   16.0   963.0   196.0   \n",
       "3       109  ...  60202  16870   377    5   2  52230.0  101.0  3721.0  4150.0   \n",
       "4        20  ...  48089   7500   461   27   2  43268.0  129.0  2733.0  1959.0   \n",
       "...     ...  ...    ...    ...   ...  ...  ..      ...    ...     ...     ...   \n",
       "522336  278  ...  10105   4154   542   50  18   8997.0    9.0   687.0   412.0   \n",
       "522337   17  ...   5543   1592   352   93  19   4548.0    6.0   815.0   174.0   \n",
       "522338   17  ...  28892   7587   272    7   2  24602.0   94.0  2608.0  1588.0   \n",
       "522339   33  ...  14027   4956   322   19   3  12807.0   29.0   793.0   398.0   \n",
       "522340   33  ...  25959   7927   952  175  85  21737.0   34.0  2700.0  1488.0   \n",
       "\n",
       "         m10  \n",
       "0       2861  \n",
       "1       4530  \n",
       "2       1088  \n",
       "3       7268  \n",
       "4       3102  \n",
       "...      ...  \n",
       "522336  1982  \n",
       "522337   703  \n",
       "522338  3050  \n",
       "522339  2177  \n",
       "522340  3607  \n",
       "\n",
       "[522341 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 商家特征处理\n",
    "groups = df_user_log.groupby(['merchant_id'])\n",
    "\n",
    "# 商家被交互行为数量 m1\n",
    "temp = groups.size().reset_index().rename(columns={0:'m1'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的user_id, item_id, cat_id, brand_id 唯一值\n",
    "temp = groups['user_id', 'item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'user_id':'m2', 'item_id':'m3', 'cat_id':'m4', 'brand_id':'m5'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 统计商家被交互的action_type 唯一值，0表示单击，1表示添加到购物车，2表示购买，3表示添加到收藏夹\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'m6', 1:'m7', 2:'m8', 3:'m9'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "\n",
    "# 按照merchant_id 统计随机负采样的个数\n",
    "temp = df_train2[df_train2['label']==-1].groupby(['merchant_id']).size().reset_index().rename(columns={0:'m10'})\n",
    "matrix = matrix.merge(temp, on='merchant_id', how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 372486,
     "status": "ok",
     "timestamp": 1591456597555,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "tAITQ6nhtiuB",
    "outputId": "4cd7d968-c510-45cc-94ec-d3e34bd10800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zhangyanqing\\.conda\\envs\\tf2.0\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>...</th>\n",
       "      <th>m10</th>\n",
       "      <th>um1</th>\n",
       "      <th>um2</th>\n",
       "      <th>um3</th>\n",
       "      <th>um4</th>\n",
       "      <th>um5</th>\n",
       "      <th>um6</th>\n",
       "      <th>um7</th>\n",
       "      <th>um8</th>\n",
       "      <th>um9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>2861</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>4530</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1088</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>7268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>3102</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>...</td>\n",
       "      <td>1982</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>3050</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>2177</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>3607</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin  age_range  gender    u1    u2  u3  \\\n",
       "0         34176         3906   0.0  train          6       0   451   256  45   \n",
       "1         34176          121   0.0  train          6       0   451   256  45   \n",
       "2         34176         4356   1.0  train          6       0   451   256  45   \n",
       "3         34176         2217   0.0  train          6       0   451   256  45   \n",
       "4        230784         4818   0.0  train          0       0    54    31  17   \n",
       "...         ...          ...   ...    ...        ...     ...   ...   ...  ..   \n",
       "522336   228479         3111   nan   test          6       0  2004  1173  71   \n",
       "522337    97919         2341   nan   test          8       1    55    29  14   \n",
       "522338    97919         3971   nan   test          8       1    55    29  14   \n",
       "522339    32639         3536   nan   test          0       0    72    46  24   \n",
       "522340    32639         3319   nan   test          0       0    72    46  24   \n",
       "\n",
       "         u4  ...   m10  um1  um2  um3  um4   um5  um6  um7  um8       um9  \n",
       "0       109  ...  2861   39   20    6    1  36.0  NaN  1.0  2.0  0.850000  \n",
       "1       109  ...  4530   14    1    1    1  13.0  NaN  1.0  NaN  0.050000  \n",
       "2       109  ...  1088   18    2    1    1  12.0  NaN  6.0  NaN  0.016667  \n",
       "3       109  ...  7268    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
       "4        20  ...  3102    8    1    1    1   7.0  NaN  1.0  NaN  0.050000  \n",
       "...     ...  ...   ...  ...  ...  ...  ...   ...  ...  ...  ...       ...  \n",
       "522336  278  ...  1982    5    2    1    1   4.0  NaN  1.0  NaN  0.016667  \n",
       "522337   17  ...   703    2    1    1    1   1.0  NaN  1.0  NaN  0.000000  \n",
       "522338   17  ...  3050   16    5    2    1  12.0  NaN  4.0  NaN  0.150000  \n",
       "522339   33  ...  2177    3    2    1    1   2.0  NaN  1.0  NaN  0.000000  \n",
       "522340   33  ...  3607   11    1    1    1  10.0  NaN  1.0  NaN  0.016667  \n",
       "\n",
       "[522341 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按照user_id, merchant_id分组\n",
    "groups = df_user_log.groupby(['user_id', 'merchant_id'])\n",
    "\n",
    "# 统计行为个数\n",
    "temp = groups.size().reset_index().rename(columns={0:'um1'})\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计item_id, cat_id, brand_id唯一个数\n",
    "temp = groups['item_id', 'cat_id', 'brand_id'].nunique().reset_index().rename(columns={'item_id':'um2', 'cat_id':'um3', 'brand_id':'um4'})\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计不同action_type唯一个数\n",
    "temp = groups['action_type'].value_counts().unstack().reset_index().rename(columns={0:'um5', 1:'um6', 2:'um7', 3:'um8'})#\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "\n",
    "# 统计时间间隔\n",
    "temp = groups['time_stamp'].agg([('first', 'min'), ('last', 'max')]).reset_index()\n",
    "temp['um9'] = (temp['last'] - temp['first']).dt.seconds/3600\n",
    "temp.drop(['first', 'last'], axis=1, inplace=True)\n",
    "matrix = matrix.merge(temp, on=['user_id', 'merchant_id'], how='left')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1597,
     "status": "ok",
     "timestamp": 1591457123542,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "FkhtndxqtmqH",
    "outputId": "7667d7e6-3a2d-4a03-ec94-8c9161ab0b90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>label</th>\n",
       "      <th>origin</th>\n",
       "      <th>u1</th>\n",
       "      <th>u2</th>\n",
       "      <th>u3</th>\n",
       "      <th>u4</th>\n",
       "      <th>u5</th>\n",
       "      <th>u6</th>\n",
       "      <th>...</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>age_8</th>\n",
       "      <th>g_0</th>\n",
       "      <th>g_1</th>\n",
       "      <th>g_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34176</td>\n",
       "      <td>3906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34176</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34176</td>\n",
       "      <td>4356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34176</td>\n",
       "      <td>2217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>451</td>\n",
       "      <td>256</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230784</td>\n",
       "      <td>4818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522336</th>\n",
       "      <td>228479</td>\n",
       "      <td>3111</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>2004</td>\n",
       "      <td>1173</td>\n",
       "      <td>71</td>\n",
       "      <td>278</td>\n",
       "      <td>282</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522337</th>\n",
       "      <td>97919</td>\n",
       "      <td>2341</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522338</th>\n",
       "      <td>97919</td>\n",
       "      <td>3971</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522339</th>\n",
       "      <td>32639</td>\n",
       "      <td>3536</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522340</th>\n",
       "      <td>32639</td>\n",
       "      <td>3319</td>\n",
       "      <td>nan</td>\n",
       "      <td>test</td>\n",
       "      <td>72</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522341 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  merchant_id label origin    u1    u2  u3   u4   u5        u6  \\\n",
       "0         34176         3906   0.0  train   451   256  45  109  108  5.833333   \n",
       "1         34176          121   0.0  train   451   256  45  109  108  5.833333   \n",
       "2         34176         4356   1.0  train   451   256  45  109  108  5.833333   \n",
       "3         34176         2217   0.0  train   451   256  45  109  108  5.833333   \n",
       "4        230784         4818   0.0  train    54    31  17   20   19  5.166667   \n",
       "...         ...          ...   ...    ...   ...   ...  ..  ...  ...       ...   \n",
       "522336   228479         3111   nan   test  2004  1173  71  278  282  6.000000   \n",
       "522337    97919         2341   nan   test    55    29  14   17   17  4.750000   \n",
       "522338    97919         3971   nan   test    55    29  14   17   17  4.750000   \n",
       "522339    32639         3536   nan   test    72    46  24   33   35  5.800000   \n",
       "522340    32639         3319   nan   test    72    46  24   33   35  5.800000   \n",
       "\n",
       "        ...  age_2  age_3  age_4  age_5  age_6  age_7  age_8  g_0  g_1  g_2  \n",
       "0       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "1       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "2       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "3       ...      0      0      0      0      1      0      0    1    0    0  \n",
       "4       ...      0      0      0      0      0      0      0    1    0    0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  ...  ...  ...  \n",
       "522336  ...      0      0      0      0      1      0      0    1    0    0  \n",
       "522337  ...      0      0      0      0      0      0      1    0    1    0  \n",
       "522338  ...      0      0      0      0      0      0      1    0    1    0  \n",
       "522339  ...      0      0      0      0      0      0      0    1    0    0  \n",
       "522340  ...      0      0      0      0      0      0      0    1    0    0  \n",
       "\n",
       "[522341 rows x 48 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用户购买点击比\n",
    "matrix['r1'] = matrix['u9']/matrix['u7'] \n",
    "\n",
    "# 商家购买点击比 不需要这个特征值，得分0.68\n",
    "matrix['r2'] = matrix['m8']/matrix['m6'] \n",
    "\n",
    "# 不同用户不同商家购买点击比\n",
    "matrix['r3'] = matrix['um7']/matrix['um5']\n",
    "\n",
    "# 填充缺失值\n",
    "matrix.fillna(0, inplace=True)\n",
    "\n",
    "# 采用one-hot编码 修改age_range字段名称为 age_0, age_1, age_2... age_8\n",
    "temp = pd.get_dummies(matrix['age_range'], prefix='age')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "\n",
    "# 采用one-hot编码 修改gender字段名称为 g_0, g_1, g_2\n",
    "temp = pd.get_dummies(matrix['gender'], prefix='g')\n",
    "matrix = pd.concat([matrix, temp], axis=1)\n",
    "\n",
    "# 删除age_range, gender字段\n",
    "matrix.drop(['age_range', 'gender'], axis=1, inplace=True)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h5CH5C2tuzu"
   },
   "source": [
    "### 训练集和测试集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1749,
     "status": "ok",
     "timestamp": 1591457129198,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "CnYNZFoGttxN",
    "outputId": "80dc95ff-7d37-4357-c197-2b9255699fd1"
   },
   "outputs": [],
   "source": [
    "# 分割训练数据和测试数据\n",
    "train_data = matrix[matrix['origin'] == 'train'].drop(['origin'], axis=1)\n",
    "test_data = matrix[matrix['origin'] == 'test'].drop(['label', 'origin'], axis=1)\n",
    "train_X, train_y = train_data.drop(['label'], axis=1), train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_LRyu0at1GM"
   },
   "source": [
    "### 模型训练（传统模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQUqgaI-BotK"
   },
   "outputs": [],
   "source": [
    "# 导入用到的模型包\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "# 将训练集进行切分，20%用于验证\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14083,
     "status": "ok",
     "timestamp": 1591454613098,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "_ufmBEx4uVo_",
    "outputId": "df9d8671-1a1c-4dc8-f35e-b584bbe46ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.63950\tvalidation_1-auc:0.62223\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.65068\tvalidation_1-auc:0.62695\n",
      "[2]\tvalidation_0-auc:0.65690\tvalidation_1-auc:0.63198\n",
      "[3]\tvalidation_0-auc:0.66365\tvalidation_1-auc:0.63812\n",
      "[4]\tvalidation_0-auc:0.66558\tvalidation_1-auc:0.63780\n",
      "[5]\tvalidation_0-auc:0.66624\tvalidation_1-auc:0.63930\n",
      "[6]\tvalidation_0-auc:0.66769\tvalidation_1-auc:0.64008\n",
      "[7]\tvalidation_0-auc:0.66793\tvalidation_1-auc:0.63998\n",
      "[8]\tvalidation_0-auc:0.67027\tvalidation_1-auc:0.64213\n",
      "[9]\tvalidation_0-auc:0.67134\tvalidation_1-auc:0.64294\n",
      "[10]\tvalidation_0-auc:0.67188\tvalidation_1-auc:0.64284\n",
      "[11]\tvalidation_0-auc:0.67296\tvalidation_1-auc:0.64432\n",
      "[12]\tvalidation_0-auc:0.67597\tvalidation_1-auc:0.64663\n",
      "[13]\tvalidation_0-auc:0.67795\tvalidation_1-auc:0.64806\n",
      "[14]\tvalidation_0-auc:0.68012\tvalidation_1-auc:0.64998\n",
      "[15]\tvalidation_0-auc:0.68138\tvalidation_1-auc:0.65131\n",
      "[16]\tvalidation_0-auc:0.68280\tvalidation_1-auc:0.65205\n",
      "[17]\tvalidation_0-auc:0.68503\tvalidation_1-auc:0.65499\n",
      "[18]\tvalidation_0-auc:0.68651\tvalidation_1-auc:0.65521\n",
      "[19]\tvalidation_0-auc:0.68845\tvalidation_1-auc:0.65621\n",
      "[20]\tvalidation_0-auc:0.68973\tvalidation_1-auc:0.65617\n",
      "[21]\tvalidation_0-auc:0.69081\tvalidation_1-auc:0.65577\n",
      "[22]\tvalidation_0-auc:0.69253\tvalidation_1-auc:0.65599\n",
      "[23]\tvalidation_0-auc:0.69390\tvalidation_1-auc:0.65632\n",
      "[24]\tvalidation_0-auc:0.69534\tvalidation_1-auc:0.65776\n",
      "[25]\tvalidation_0-auc:0.69636\tvalidation_1-auc:0.65839\n",
      "[26]\tvalidation_0-auc:0.69714\tvalidation_1-auc:0.65923\n",
      "[27]\tvalidation_0-auc:0.69867\tvalidation_1-auc:0.66083\n",
      "[28]\tvalidation_0-auc:0.69933\tvalidation_1-auc:0.66088\n",
      "[29]\tvalidation_0-auc:0.69993\tvalidation_1-auc:0.66121\n",
      "[30]\tvalidation_0-auc:0.70025\tvalidation_1-auc:0.66133\n",
      "[31]\tvalidation_0-auc:0.70088\tvalidation_1-auc:0.66104\n",
      "[32]\tvalidation_0-auc:0.70164\tvalidation_1-auc:0.66179\n",
      "[33]\tvalidation_0-auc:0.70243\tvalidation_1-auc:0.66203\n",
      "[34]\tvalidation_0-auc:0.70317\tvalidation_1-auc:0.66228\n",
      "[35]\tvalidation_0-auc:0.70387\tvalidation_1-auc:0.66207\n",
      "[36]\tvalidation_0-auc:0.70510\tvalidation_1-auc:0.66337\n",
      "[37]\tvalidation_0-auc:0.70563\tvalidation_1-auc:0.66322\n",
      "[38]\tvalidation_0-auc:0.70617\tvalidation_1-auc:0.66331\n",
      "[39]\tvalidation_0-auc:0.70687\tvalidation_1-auc:0.66305\n",
      "[40]\tvalidation_0-auc:0.70786\tvalidation_1-auc:0.66338\n",
      "[41]\tvalidation_0-auc:0.70868\tvalidation_1-auc:0.66358\n",
      "[42]\tvalidation_0-auc:0.70968\tvalidation_1-auc:0.66402\n",
      "[43]\tvalidation_0-auc:0.71050\tvalidation_1-auc:0.66474\n",
      "[44]\tvalidation_0-auc:0.71125\tvalidation_1-auc:0.66458\n",
      "[45]\tvalidation_0-auc:0.71185\tvalidation_1-auc:0.66499\n",
      "[46]\tvalidation_0-auc:0.71248\tvalidation_1-auc:0.66565\n",
      "[47]\tvalidation_0-auc:0.71317\tvalidation_1-auc:0.66567\n",
      "[48]\tvalidation_0-auc:0.71361\tvalidation_1-auc:0.66543\n",
      "[49]\tvalidation_0-auc:0.71428\tvalidation_1-auc:0.66570\n",
      "[50]\tvalidation_0-auc:0.71496\tvalidation_1-auc:0.66568\n",
      "[51]\tvalidation_0-auc:0.71566\tvalidation_1-auc:0.66547\n",
      "[52]\tvalidation_0-auc:0.71616\tvalidation_1-auc:0.66520\n",
      "[53]\tvalidation_0-auc:0.71691\tvalidation_1-auc:0.66585\n",
      "[54]\tvalidation_0-auc:0.71749\tvalidation_1-auc:0.66546\n",
      "[55]\tvalidation_0-auc:0.71790\tvalidation_1-auc:0.66561\n",
      "[56]\tvalidation_0-auc:0.71857\tvalidation_1-auc:0.66548\n",
      "[57]\tvalidation_0-auc:0.71886\tvalidation_1-auc:0.66541\n",
      "[58]\tvalidation_0-auc:0.71939\tvalidation_1-auc:0.66524\n",
      "[59]\tvalidation_0-auc:0.71998\tvalidation_1-auc:0.66535\n",
      "[60]\tvalidation_0-auc:0.72041\tvalidation_1-auc:0.66555\n",
      "[61]\tvalidation_0-auc:0.72109\tvalidation_1-auc:0.66581\n",
      "[62]\tvalidation_0-auc:0.72165\tvalidation_1-auc:0.66593\n",
      "[63]\tvalidation_0-auc:0.72199\tvalidation_1-auc:0.66595\n",
      "[64]\tvalidation_0-auc:0.72247\tvalidation_1-auc:0.66610\n",
      "[65]\tvalidation_0-auc:0.72283\tvalidation_1-auc:0.66596\n",
      "[66]\tvalidation_0-auc:0.72348\tvalidation_1-auc:0.66627\n",
      "[67]\tvalidation_0-auc:0.72417\tvalidation_1-auc:0.66655\n",
      "[68]\tvalidation_0-auc:0.72490\tvalidation_1-auc:0.66621\n",
      "[69]\tvalidation_0-auc:0.72564\tvalidation_1-auc:0.66614\n",
      "[70]\tvalidation_0-auc:0.72592\tvalidation_1-auc:0.66633\n",
      "[71]\tvalidation_0-auc:0.72624\tvalidation_1-auc:0.66614\n",
      "[72]\tvalidation_0-auc:0.72707\tvalidation_1-auc:0.66595\n",
      "[73]\tvalidation_0-auc:0.72751\tvalidation_1-auc:0.66626\n",
      "[74]\tvalidation_0-auc:0.72778\tvalidation_1-auc:0.66617\n",
      "[75]\tvalidation_0-auc:0.72831\tvalidation_1-auc:0.66599\n",
      "[76]\tvalidation_0-auc:0.72900\tvalidation_1-auc:0.66590\n",
      "[77]\tvalidation_0-auc:0.72929\tvalidation_1-auc:0.66599\n",
      "Stopping. Best iteration:\n",
      "[67]\tvalidation_0-auc:0.72417\tvalidation_1-auc:0.66655\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eta=0.3, gamma=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=300, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=0.8, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    eta=0.3,    \n",
    "    seed=42     \n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='auc', \n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    verbose=True,\n",
    "    #早停法，如果auc在10epoch没有进步就stop\n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90922,
     "status": "ok",
     "timestamp": 1591457231215,
     "user": {
      "displayName": "无名氏",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gia-u54D73Stf2HHMQ4Edqb8MK6s-GZPMQNEVaA=s64",
      "userId": "11633411362684286628"
     },
     "user_tz": -120
    },
    "id": "zZ0s2nxRDbIq",
    "outputId": "1ca6b7b0-faed-447f-97c2-812324c8f19c",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.637646\ttraining's binary_logloss: 0.230419\tvalid_1's auc: 0.619757\tvalid_1's binary_logloss: 0.227396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.651315\ttraining's binary_logloss: 0.230089\tvalid_1's auc: 0.628252\tvalid_1's binary_logloss: 0.227166\n",
      "[3]\ttraining's auc: 0.657335\ttraining's binary_logloss: 0.229767\tvalid_1's auc: 0.632352\tvalid_1's binary_logloss: 0.226924\n",
      "[4]\ttraining's auc: 0.659936\ttraining's binary_logloss: 0.229471\tvalid_1's auc: 0.635931\tvalid_1's binary_logloss: 0.226691\n",
      "[5]\ttraining's auc: 0.664412\ttraining's binary_logloss: 0.229169\tvalid_1's auc: 0.64034\tvalid_1's binary_logloss: 0.226462\n",
      "[6]\ttraining's auc: 0.66608\ttraining's binary_logloss: 0.228892\tvalid_1's auc: 0.642233\tvalid_1's binary_logloss: 0.226248\n",
      "[7]\ttraining's auc: 0.666479\ttraining's binary_logloss: 0.228618\tvalid_1's auc: 0.641947\tvalid_1's binary_logloss: 0.226049\n",
      "[8]\ttraining's auc: 0.666614\ttraining's binary_logloss: 0.228349\tvalid_1's auc: 0.642071\tvalid_1's binary_logloss: 0.225845\n",
      "[9]\ttraining's auc: 0.667688\ttraining's binary_logloss: 0.228067\tvalid_1's auc: 0.643549\tvalid_1's binary_logloss: 0.225637\n",
      "[10]\ttraining's auc: 0.668172\ttraining's binary_logloss: 0.227792\tvalid_1's auc: 0.644121\tvalid_1's binary_logloss: 0.225434\n",
      "[11]\ttraining's auc: 0.668772\ttraining's binary_logloss: 0.227541\tvalid_1's auc: 0.644166\tvalid_1's binary_logloss: 0.225256\n",
      "[12]\ttraining's auc: 0.668978\ttraining's binary_logloss: 0.227301\tvalid_1's auc: 0.643984\tvalid_1's binary_logloss: 0.225076\n",
      "[13]\ttraining's auc: 0.669311\ttraining's binary_logloss: 0.227072\tvalid_1's auc: 0.6444\tvalid_1's binary_logloss: 0.224909\n",
      "[14]\ttraining's auc: 0.6692\ttraining's binary_logloss: 0.226849\tvalid_1's auc: 0.644027\tvalid_1's binary_logloss: 0.224758\n",
      "[15]\ttraining's auc: 0.669544\ttraining's binary_logloss: 0.226645\tvalid_1's auc: 0.644045\tvalid_1's binary_logloss: 0.224615\n",
      "[16]\ttraining's auc: 0.669984\ttraining's binary_logloss: 0.226442\tvalid_1's auc: 0.644339\tvalid_1's binary_logloss: 0.224477\n",
      "[17]\ttraining's auc: 0.670096\ttraining's binary_logloss: 0.226235\tvalid_1's auc: 0.644178\tvalid_1's binary_logloss: 0.224334\n",
      "[18]\ttraining's auc: 0.670045\ttraining's binary_logloss: 0.22603\tvalid_1's auc: 0.643819\tvalid_1's binary_logloss: 0.224193\n",
      "[19]\ttraining's auc: 0.670642\ttraining's binary_logloss: 0.225845\tvalid_1's auc: 0.643943\tvalid_1's binary_logloss: 0.224071\n",
      "[20]\ttraining's auc: 0.670485\ttraining's binary_logloss: 0.225657\tvalid_1's auc: 0.643726\tvalid_1's binary_logloss: 0.223947\n",
      "[21]\ttraining's auc: 0.67111\ttraining's binary_logloss: 0.225464\tvalid_1's auc: 0.64387\tvalid_1's binary_logloss: 0.22381\n",
      "[22]\ttraining's auc: 0.67153\ttraining's binary_logloss: 0.225278\tvalid_1's auc: 0.643971\tvalid_1's binary_logloss: 0.223682\n",
      "[23]\ttraining's auc: 0.671665\ttraining's binary_logloss: 0.225108\tvalid_1's auc: 0.643917\tvalid_1's binary_logloss: 0.223562\n",
      "[24]\ttraining's auc: 0.672526\ttraining's binary_logloss: 0.224927\tvalid_1's auc: 0.644456\tvalid_1's binary_logloss: 0.223432\n",
      "[25]\ttraining's auc: 0.672681\ttraining's binary_logloss: 0.224757\tvalid_1's auc: 0.644531\tvalid_1's binary_logloss: 0.223317\n",
      "[26]\ttraining's auc: 0.672585\ttraining's binary_logloss: 0.224593\tvalid_1's auc: 0.644296\tvalid_1's binary_logloss: 0.223209\n",
      "[27]\ttraining's auc: 0.672764\ttraining's binary_logloss: 0.224431\tvalid_1's auc: 0.64434\tvalid_1's binary_logloss: 0.223101\n",
      "[28]\ttraining's auc: 0.672767\ttraining's binary_logloss: 0.224284\tvalid_1's auc: 0.644327\tvalid_1's binary_logloss: 0.223005\n",
      "[29]\ttraining's auc: 0.673358\ttraining's binary_logloss: 0.224128\tvalid_1's auc: 0.644919\tvalid_1's binary_logloss: 0.222895\n",
      "[30]\ttraining's auc: 0.674046\ttraining's binary_logloss: 0.223976\tvalid_1's auc: 0.645378\tvalid_1's binary_logloss: 0.222785\n",
      "[31]\ttraining's auc: 0.674268\ttraining's binary_logloss: 0.223836\tvalid_1's auc: 0.645124\tvalid_1's binary_logloss: 0.222692\n",
      "[32]\ttraining's auc: 0.674611\ttraining's binary_logloss: 0.223688\tvalid_1's auc: 0.645123\tvalid_1's binary_logloss: 0.222594\n",
      "[33]\ttraining's auc: 0.675075\ttraining's binary_logloss: 0.22354\tvalid_1's auc: 0.645438\tvalid_1's binary_logloss: 0.222495\n",
      "[34]\ttraining's auc: 0.67549\ttraining's binary_logloss: 0.223397\tvalid_1's auc: 0.645697\tvalid_1's binary_logloss: 0.222394\n",
      "[35]\ttraining's auc: 0.675862\ttraining's binary_logloss: 0.223266\tvalid_1's auc: 0.646051\tvalid_1's binary_logloss: 0.222305\n",
      "[36]\ttraining's auc: 0.676392\ttraining's binary_logloss: 0.223123\tvalid_1's auc: 0.64641\tvalid_1's binary_logloss: 0.222204\n",
      "[37]\ttraining's auc: 0.676517\ttraining's binary_logloss: 0.223002\tvalid_1's auc: 0.646254\tvalid_1's binary_logloss: 0.222131\n",
      "[38]\ttraining's auc: 0.677029\ttraining's binary_logloss: 0.222862\tvalid_1's auc: 0.646731\tvalid_1's binary_logloss: 0.22204\n",
      "[39]\ttraining's auc: 0.677413\ttraining's binary_logloss: 0.222741\tvalid_1's auc: 0.646771\tvalid_1's binary_logloss: 0.221963\n",
      "[40]\ttraining's auc: 0.677524\ttraining's binary_logloss: 0.222617\tvalid_1's auc: 0.646793\tvalid_1's binary_logloss: 0.221882\n",
      "[41]\ttraining's auc: 0.677586\ttraining's binary_logloss: 0.222495\tvalid_1's auc: 0.646815\tvalid_1's binary_logloss: 0.221805\n",
      "[42]\ttraining's auc: 0.677908\ttraining's binary_logloss: 0.222376\tvalid_1's auc: 0.646937\tvalid_1's binary_logloss: 0.221726\n",
      "[43]\ttraining's auc: 0.67805\ttraining's binary_logloss: 0.222264\tvalid_1's auc: 0.646873\tvalid_1's binary_logloss: 0.221662\n",
      "[44]\ttraining's auc: 0.678283\ttraining's binary_logloss: 0.222156\tvalid_1's auc: 0.646863\tvalid_1's binary_logloss: 0.221601\n",
      "[45]\ttraining's auc: 0.678727\ttraining's binary_logloss: 0.222048\tvalid_1's auc: 0.64707\tvalid_1's binary_logloss: 0.221534\n",
      "[46]\ttraining's auc: 0.678944\ttraining's binary_logloss: 0.221941\tvalid_1's auc: 0.647105\tvalid_1's binary_logloss: 0.22147\n",
      "[47]\ttraining's auc: 0.67915\ttraining's binary_logloss: 0.221841\tvalid_1's auc: 0.647124\tvalid_1's binary_logloss: 0.221409\n",
      "[48]\ttraining's auc: 0.679291\ttraining's binary_logloss: 0.221744\tvalid_1's auc: 0.64708\tvalid_1's binary_logloss: 0.221352\n",
      "[49]\ttraining's auc: 0.679689\ttraining's binary_logloss: 0.221629\tvalid_1's auc: 0.647325\tvalid_1's binary_logloss: 0.221283\n",
      "[50]\ttraining's auc: 0.679945\ttraining's binary_logloss: 0.221524\tvalid_1's auc: 0.647543\tvalid_1's binary_logloss: 0.221218\n",
      "[51]\ttraining's auc: 0.680134\ttraining's binary_logloss: 0.221427\tvalid_1's auc: 0.647837\tvalid_1's binary_logloss: 0.221156\n",
      "[52]\ttraining's auc: 0.680277\ttraining's binary_logloss: 0.221331\tvalid_1's auc: 0.648008\tvalid_1's binary_logloss: 0.221095\n",
      "[53]\ttraining's auc: 0.680851\ttraining's binary_logloss: 0.221228\tvalid_1's auc: 0.648456\tvalid_1's binary_logloss: 0.221035\n",
      "[54]\ttraining's auc: 0.681252\ttraining's binary_logloss: 0.221129\tvalid_1's auc: 0.648715\tvalid_1's binary_logloss: 0.220976\n",
      "[55]\ttraining's auc: 0.681398\ttraining's binary_logloss: 0.221042\tvalid_1's auc: 0.648801\tvalid_1's binary_logloss: 0.22092\n",
      "[56]\ttraining's auc: 0.681664\ttraining's binary_logloss: 0.220951\tvalid_1's auc: 0.648898\tvalid_1's binary_logloss: 0.220871\n",
      "[57]\ttraining's auc: 0.681816\ttraining's binary_logloss: 0.220862\tvalid_1's auc: 0.648962\tvalid_1's binary_logloss: 0.220817\n",
      "[58]\ttraining's auc: 0.681919\ttraining's binary_logloss: 0.220771\tvalid_1's auc: 0.648993\tvalid_1's binary_logloss: 0.220763\n",
      "[59]\ttraining's auc: 0.68222\ttraining's binary_logloss: 0.220688\tvalid_1's auc: 0.64899\tvalid_1's binary_logloss: 0.220715\n",
      "[60]\ttraining's auc: 0.682368\ttraining's binary_logloss: 0.220606\tvalid_1's auc: 0.649062\tvalid_1's binary_logloss: 0.220666\n",
      "[61]\ttraining's auc: 0.68267\ttraining's binary_logloss: 0.220515\tvalid_1's auc: 0.649237\tvalid_1's binary_logloss: 0.220607\n",
      "[62]\ttraining's auc: 0.682821\ttraining's binary_logloss: 0.220432\tvalid_1's auc: 0.649247\tvalid_1's binary_logloss: 0.220565\n",
      "[63]\ttraining's auc: 0.683014\ttraining's binary_logloss: 0.220341\tvalid_1's auc: 0.649426\tvalid_1's binary_logloss: 0.220514\n",
      "[64]\ttraining's auc: 0.683299\ttraining's binary_logloss: 0.220267\tvalid_1's auc: 0.649479\tvalid_1's binary_logloss: 0.220473\n",
      "[65]\ttraining's auc: 0.683508\ttraining's binary_logloss: 0.220188\tvalid_1's auc: 0.649636\tvalid_1's binary_logloss: 0.220427\n",
      "[66]\ttraining's auc: 0.68371\ttraining's binary_logloss: 0.22011\tvalid_1's auc: 0.649813\tvalid_1's binary_logloss: 0.220378\n",
      "[67]\ttraining's auc: 0.683916\ttraining's binary_logloss: 0.220029\tvalid_1's auc: 0.649972\tvalid_1's binary_logloss: 0.220333\n",
      "[68]\ttraining's auc: 0.684592\ttraining's binary_logloss: 0.219926\tvalid_1's auc: 0.650478\tvalid_1's binary_logloss: 0.220271\n",
      "[69]\ttraining's auc: 0.684674\ttraining's binary_logloss: 0.219858\tvalid_1's auc: 0.650511\tvalid_1's binary_logloss: 0.220235\n",
      "[70]\ttraining's auc: 0.68501\ttraining's binary_logloss: 0.219768\tvalid_1's auc: 0.650811\tvalid_1's binary_logloss: 0.22018\n",
      "[71]\ttraining's auc: 0.685484\ttraining's binary_logloss: 0.219672\tvalid_1's auc: 0.65109\tvalid_1's binary_logloss: 0.220122\n",
      "[72]\ttraining's auc: 0.685998\ttraining's binary_logloss: 0.219592\tvalid_1's auc: 0.651212\tvalid_1's binary_logloss: 0.220078\n",
      "[73]\ttraining's auc: 0.686163\ttraining's binary_logloss: 0.219514\tvalid_1's auc: 0.651337\tvalid_1's binary_logloss: 0.220033\n",
      "[74]\ttraining's auc: 0.686286\ttraining's binary_logloss: 0.219438\tvalid_1's auc: 0.651473\tvalid_1's binary_logloss: 0.219989\n",
      "[75]\ttraining's auc: 0.686668\ttraining's binary_logloss: 0.219353\tvalid_1's auc: 0.651748\tvalid_1's binary_logloss: 0.219939\n",
      "[76]\ttraining's auc: 0.687129\ttraining's binary_logloss: 0.219269\tvalid_1's auc: 0.651987\tvalid_1's binary_logloss: 0.219888\n",
      "[77]\ttraining's auc: 0.687388\ttraining's binary_logloss: 0.219203\tvalid_1's auc: 0.652039\tvalid_1's binary_logloss: 0.219855\n",
      "[78]\ttraining's auc: 0.687626\ttraining's binary_logloss: 0.219133\tvalid_1's auc: 0.652291\tvalid_1's binary_logloss: 0.219808\n",
      "[79]\ttraining's auc: 0.687951\ttraining's binary_logloss: 0.219058\tvalid_1's auc: 0.652417\tvalid_1's binary_logloss: 0.219771\n",
      "[80]\ttraining's auc: 0.68828\ttraining's binary_logloss: 0.218981\tvalid_1's auc: 0.652503\tvalid_1's binary_logloss: 0.219737\n",
      "[81]\ttraining's auc: 0.68872\ttraining's binary_logloss: 0.218902\tvalid_1's auc: 0.652866\tvalid_1's binary_logloss: 0.219687\n",
      "[82]\ttraining's auc: 0.688951\ttraining's binary_logloss: 0.218834\tvalid_1's auc: 0.652915\tvalid_1's binary_logloss: 0.219651\n",
      "[83]\ttraining's auc: 0.689182\ttraining's binary_logloss: 0.21876\tvalid_1's auc: 0.652954\tvalid_1's binary_logloss: 0.219616\n",
      "[84]\ttraining's auc: 0.689415\ttraining's binary_logloss: 0.218686\tvalid_1's auc: 0.652938\tvalid_1's binary_logloss: 0.219583\n",
      "[85]\ttraining's auc: 0.689611\ttraining's binary_logloss: 0.218624\tvalid_1's auc: 0.652836\tvalid_1's binary_logloss: 0.219565\n",
      "[86]\ttraining's auc: 0.689847\ttraining's binary_logloss: 0.21856\tvalid_1's auc: 0.652885\tvalid_1's binary_logloss: 0.219537\n",
      "[87]\ttraining's auc: 0.690066\ttraining's binary_logloss: 0.218501\tvalid_1's auc: 0.652773\tvalid_1's binary_logloss: 0.21952\n",
      "[88]\ttraining's auc: 0.690372\ttraining's binary_logloss: 0.218433\tvalid_1's auc: 0.652909\tvalid_1's binary_logloss: 0.219485\n",
      "[89]\ttraining's auc: 0.690556\ttraining's binary_logloss: 0.218374\tvalid_1's auc: 0.652994\tvalid_1's binary_logloss: 0.219455\n",
      "[90]\ttraining's auc: 0.690717\ttraining's binary_logloss: 0.218316\tvalid_1's auc: 0.653009\tvalid_1's binary_logloss: 0.219426\n",
      "[91]\ttraining's auc: 0.690951\ttraining's binary_logloss: 0.218257\tvalid_1's auc: 0.653031\tvalid_1's binary_logloss: 0.219405\n",
      "[92]\ttraining's auc: 0.691212\ttraining's binary_logloss: 0.218196\tvalid_1's auc: 0.653189\tvalid_1's binary_logloss: 0.219374\n",
      "[93]\ttraining's auc: 0.691341\ttraining's binary_logloss: 0.218142\tvalid_1's auc: 0.653274\tvalid_1's binary_logloss: 0.219348\n",
      "[94]\ttraining's auc: 0.691464\ttraining's binary_logloss: 0.218091\tvalid_1's auc: 0.653306\tvalid_1's binary_logloss: 0.219322\n",
      "[95]\ttraining's auc: 0.691659\ttraining's binary_logloss: 0.218037\tvalid_1's auc: 0.653368\tvalid_1's binary_logloss: 0.219298\n",
      "[96]\ttraining's auc: 0.691886\ttraining's binary_logloss: 0.217977\tvalid_1's auc: 0.653405\tvalid_1's binary_logloss: 0.219275\n",
      "[97]\ttraining's auc: 0.692116\ttraining's binary_logloss: 0.217916\tvalid_1's auc: 0.653461\tvalid_1's binary_logloss: 0.219251\n",
      "[98]\ttraining's auc: 0.692346\ttraining's binary_logloss: 0.217861\tvalid_1's auc: 0.653514\tvalid_1's binary_logloss: 0.219228\n",
      "[99]\ttraining's auc: 0.692613\ttraining's binary_logloss: 0.217795\tvalid_1's auc: 0.65373\tvalid_1's binary_logloss: 0.219195\n",
      "[100]\ttraining's auc: 0.693038\ttraining's binary_logloss: 0.217725\tvalid_1's auc: 0.654029\tvalid_1's binary_logloss: 0.219152\n",
      "[101]\ttraining's auc: 0.693613\ttraining's binary_logloss: 0.217645\tvalid_1's auc: 0.654482\tvalid_1's binary_logloss: 0.219102\n",
      "[102]\ttraining's auc: 0.693835\ttraining's binary_logloss: 0.217587\tvalid_1's auc: 0.654561\tvalid_1's binary_logloss: 0.219072\n",
      "[103]\ttraining's auc: 0.69407\ttraining's binary_logloss: 0.217538\tvalid_1's auc: 0.654694\tvalid_1's binary_logloss: 0.21905\n",
      "[104]\ttraining's auc: 0.694354\ttraining's binary_logloss: 0.21748\tvalid_1's auc: 0.654831\tvalid_1's binary_logloss: 0.219028\n",
      "[105]\ttraining's auc: 0.694698\ttraining's binary_logloss: 0.217414\tvalid_1's auc: 0.655066\tvalid_1's binary_logloss: 0.218994\n",
      "[106]\ttraining's auc: 0.694933\ttraining's binary_logloss: 0.217358\tvalid_1's auc: 0.655169\tvalid_1's binary_logloss: 0.218968\n",
      "[107]\ttraining's auc: 0.695123\ttraining's binary_logloss: 0.217305\tvalid_1's auc: 0.655303\tvalid_1's binary_logloss: 0.21894\n",
      "[108]\ttraining's auc: 0.695332\ttraining's binary_logloss: 0.217254\tvalid_1's auc: 0.655316\tvalid_1's binary_logloss: 0.218919\n",
      "[109]\ttraining's auc: 0.695649\ttraining's binary_logloss: 0.217197\tvalid_1's auc: 0.655483\tvalid_1's binary_logloss: 0.218892\n",
      "[110]\ttraining's auc: 0.695786\ttraining's binary_logloss: 0.21715\tvalid_1's auc: 0.655497\tvalid_1's binary_logloss: 0.218876\n",
      "[111]\ttraining's auc: 0.696092\ttraining's binary_logloss: 0.217095\tvalid_1's auc: 0.655636\tvalid_1's binary_logloss: 0.218853\n",
      "[112]\ttraining's auc: 0.696274\ttraining's binary_logloss: 0.217047\tvalid_1's auc: 0.655647\tvalid_1's binary_logloss: 0.218835\n",
      "[113]\ttraining's auc: 0.696615\ttraining's binary_logloss: 0.216989\tvalid_1's auc: 0.655835\tvalid_1's binary_logloss: 0.21881\n",
      "[114]\ttraining's auc: 0.696941\ttraining's binary_logloss: 0.216936\tvalid_1's auc: 0.655918\tvalid_1's binary_logloss: 0.218791\n",
      "[115]\ttraining's auc: 0.697181\ttraining's binary_logloss: 0.216885\tvalid_1's auc: 0.656039\tvalid_1's binary_logloss: 0.218771\n",
      "[116]\ttraining's auc: 0.697504\ttraining's binary_logloss: 0.216834\tvalid_1's auc: 0.656112\tvalid_1's binary_logloss: 0.218751\n",
      "[117]\ttraining's auc: 0.697876\ttraining's binary_logloss: 0.216781\tvalid_1's auc: 0.656226\tvalid_1's binary_logloss: 0.218729\n",
      "[118]\ttraining's auc: 0.698196\ttraining's binary_logloss: 0.216726\tvalid_1's auc: 0.656266\tvalid_1's binary_logloss: 0.218708\n",
      "[119]\ttraining's auc: 0.698659\ttraining's binary_logloss: 0.216666\tvalid_1's auc: 0.656531\tvalid_1's binary_logloss: 0.21868\n",
      "[120]\ttraining's auc: 0.698981\ttraining's binary_logloss: 0.216615\tvalid_1's auc: 0.656564\tvalid_1's binary_logloss: 0.21866\n",
      "[121]\ttraining's auc: 0.699211\ttraining's binary_logloss: 0.216571\tvalid_1's auc: 0.656694\tvalid_1's binary_logloss: 0.218639\n",
      "[122]\ttraining's auc: 0.699518\ttraining's binary_logloss: 0.216522\tvalid_1's auc: 0.656855\tvalid_1's binary_logloss: 0.218611\n",
      "[123]\ttraining's auc: 0.699732\ttraining's binary_logloss: 0.216475\tvalid_1's auc: 0.656966\tvalid_1's binary_logloss: 0.218591\n",
      "[124]\ttraining's auc: 0.700009\ttraining's binary_logloss: 0.216427\tvalid_1's auc: 0.657113\tvalid_1's binary_logloss: 0.218571\n",
      "[125]\ttraining's auc: 0.700297\ttraining's binary_logloss: 0.216382\tvalid_1's auc: 0.657147\tvalid_1's binary_logloss: 0.218562\n",
      "[126]\ttraining's auc: 0.700559\ttraining's binary_logloss: 0.216338\tvalid_1's auc: 0.657122\tvalid_1's binary_logloss: 0.218554\n",
      "[127]\ttraining's auc: 0.700886\ttraining's binary_logloss: 0.216289\tvalid_1's auc: 0.657232\tvalid_1's binary_logloss: 0.218533\n",
      "[128]\ttraining's auc: 0.701106\ttraining's binary_logloss: 0.216242\tvalid_1's auc: 0.657305\tvalid_1's binary_logloss: 0.218518\n",
      "[129]\ttraining's auc: 0.701302\ttraining's binary_logloss: 0.2162\tvalid_1's auc: 0.65736\tvalid_1's binary_logloss: 0.218503\n",
      "[130]\ttraining's auc: 0.701494\ttraining's binary_logloss: 0.216157\tvalid_1's auc: 0.6574\tvalid_1's binary_logloss: 0.218489\n",
      "[131]\ttraining's auc: 0.701829\ttraining's binary_logloss: 0.216106\tvalid_1's auc: 0.657543\tvalid_1's binary_logloss: 0.218464\n",
      "[132]\ttraining's auc: 0.702045\ttraining's binary_logloss: 0.216063\tvalid_1's auc: 0.657622\tvalid_1's binary_logloss: 0.218445\n",
      "[133]\ttraining's auc: 0.702294\ttraining's binary_logloss: 0.216015\tvalid_1's auc: 0.657736\tvalid_1's binary_logloss: 0.218427\n",
      "[134]\ttraining's auc: 0.702538\ttraining's binary_logloss: 0.215974\tvalid_1's auc: 0.657707\tvalid_1's binary_logloss: 0.21842\n",
      "[135]\ttraining's auc: 0.702788\ttraining's binary_logloss: 0.215926\tvalid_1's auc: 0.65784\tvalid_1's binary_logloss: 0.218395\n",
      "[136]\ttraining's auc: 0.702972\ttraining's binary_logloss: 0.215882\tvalid_1's auc: 0.657829\tvalid_1's binary_logloss: 0.218381\n",
      "[137]\ttraining's auc: 0.703191\ttraining's binary_logloss: 0.215838\tvalid_1's auc: 0.657883\tvalid_1's binary_logloss: 0.21837\n",
      "[138]\ttraining's auc: 0.703369\ttraining's binary_logloss: 0.215799\tvalid_1's auc: 0.657856\tvalid_1's binary_logloss: 0.218364\n",
      "[139]\ttraining's auc: 0.703741\ttraining's binary_logloss: 0.215743\tvalid_1's auc: 0.658002\tvalid_1's binary_logloss: 0.218345\n",
      "[140]\ttraining's auc: 0.704049\ttraining's binary_logloss: 0.215694\tvalid_1's auc: 0.65811\tvalid_1's binary_logloss: 0.218326\n",
      "[141]\ttraining's auc: 0.704252\ttraining's binary_logloss: 0.215651\tvalid_1's auc: 0.658118\tvalid_1's binary_logloss: 0.218313\n",
      "[142]\ttraining's auc: 0.70455\ttraining's binary_logloss: 0.215601\tvalid_1's auc: 0.658212\tvalid_1's binary_logloss: 0.218294\n",
      "[143]\ttraining's auc: 0.704744\ttraining's binary_logloss: 0.215558\tvalid_1's auc: 0.658382\tvalid_1's binary_logloss: 0.218274\n",
      "[144]\ttraining's auc: 0.704978\ttraining's binary_logloss: 0.215509\tvalid_1's auc: 0.658569\tvalid_1's binary_logloss: 0.218248\n",
      "[145]\ttraining's auc: 0.705134\ttraining's binary_logloss: 0.215466\tvalid_1's auc: 0.658542\tvalid_1's binary_logloss: 0.218242\n",
      "[146]\ttraining's auc: 0.705327\ttraining's binary_logloss: 0.215428\tvalid_1's auc: 0.658457\tvalid_1's binary_logloss: 0.218243\n",
      "[147]\ttraining's auc: 0.705527\ttraining's binary_logloss: 0.215385\tvalid_1's auc: 0.658478\tvalid_1's binary_logloss: 0.21823\n",
      "[148]\ttraining's auc: 0.705788\ttraining's binary_logloss: 0.215338\tvalid_1's auc: 0.658558\tvalid_1's binary_logloss: 0.218211\n",
      "[149]\ttraining's auc: 0.706077\ttraining's binary_logloss: 0.215291\tvalid_1's auc: 0.658688\tvalid_1's binary_logloss: 0.218198\n",
      "[150]\ttraining's auc: 0.706324\ttraining's binary_logloss: 0.215247\tvalid_1's auc: 0.658701\tvalid_1's binary_logloss: 0.218188\n",
      "[151]\ttraining's auc: 0.706705\ttraining's binary_logloss: 0.215186\tvalid_1's auc: 0.658925\tvalid_1's binary_logloss: 0.218154\n",
      "[152]\ttraining's auc: 0.706925\ttraining's binary_logloss: 0.215142\tvalid_1's auc: 0.659037\tvalid_1's binary_logloss: 0.218131\n",
      "[153]\ttraining's auc: 0.707228\ttraining's binary_logloss: 0.215091\tvalid_1's auc: 0.659112\tvalid_1's binary_logloss: 0.218118\n",
      "[154]\ttraining's auc: 0.707491\ttraining's binary_logloss: 0.215039\tvalid_1's auc: 0.659204\tvalid_1's binary_logloss: 0.218102\n",
      "[155]\ttraining's auc: 0.707751\ttraining's binary_logloss: 0.214994\tvalid_1's auc: 0.659367\tvalid_1's binary_logloss: 0.218081\n",
      "[156]\ttraining's auc: 0.707979\ttraining's binary_logloss: 0.214953\tvalid_1's auc: 0.659321\tvalid_1's binary_logloss: 0.218078\n",
      "[157]\ttraining's auc: 0.708243\ttraining's binary_logloss: 0.214915\tvalid_1's auc: 0.659383\tvalid_1's binary_logloss: 0.218062\n",
      "[158]\ttraining's auc: 0.708556\ttraining's binary_logloss: 0.214869\tvalid_1's auc: 0.65953\tvalid_1's binary_logloss: 0.218044\n",
      "[159]\ttraining's auc: 0.708672\ttraining's binary_logloss: 0.214832\tvalid_1's auc: 0.659521\tvalid_1's binary_logloss: 0.218037\n",
      "[160]\ttraining's auc: 0.708841\ttraining's binary_logloss: 0.214794\tvalid_1's auc: 0.659567\tvalid_1's binary_logloss: 0.218026\n",
      "[161]\ttraining's auc: 0.70907\ttraining's binary_logloss: 0.214755\tvalid_1's auc: 0.659709\tvalid_1's binary_logloss: 0.218008\n",
      "[162]\ttraining's auc: 0.709316\ttraining's binary_logloss: 0.214714\tvalid_1's auc: 0.659834\tvalid_1's binary_logloss: 0.21799\n",
      "[163]\ttraining's auc: 0.709491\ttraining's binary_logloss: 0.214677\tvalid_1's auc: 0.659857\tvalid_1's binary_logloss: 0.21798\n",
      "[164]\ttraining's auc: 0.709677\ttraining's binary_logloss: 0.214639\tvalid_1's auc: 0.659871\tvalid_1's binary_logloss: 0.217972\n",
      "[165]\ttraining's auc: 0.709844\ttraining's binary_logloss: 0.214601\tvalid_1's auc: 0.659901\tvalid_1's binary_logloss: 0.217963\n",
      "[166]\ttraining's auc: 0.710174\ttraining's binary_logloss: 0.214553\tvalid_1's auc: 0.660175\tvalid_1's binary_logloss: 0.217934\n",
      "[167]\ttraining's auc: 0.710374\ttraining's binary_logloss: 0.214512\tvalid_1's auc: 0.660265\tvalid_1's binary_logloss: 0.217919\n",
      "[168]\ttraining's auc: 0.710581\ttraining's binary_logloss: 0.214468\tvalid_1's auc: 0.660306\tvalid_1's binary_logloss: 0.217906\n",
      "[169]\ttraining's auc: 0.710805\ttraining's binary_logloss: 0.214429\tvalid_1's auc: 0.660342\tvalid_1's binary_logloss: 0.217899\n",
      "[170]\ttraining's auc: 0.710928\ttraining's binary_logloss: 0.214395\tvalid_1's auc: 0.660364\tvalid_1's binary_logloss: 0.217894\n",
      "[171]\ttraining's auc: 0.711253\ttraining's binary_logloss: 0.214347\tvalid_1's auc: 0.660519\tvalid_1's binary_logloss: 0.217874\n",
      "[172]\ttraining's auc: 0.711545\ttraining's binary_logloss: 0.2143\tvalid_1's auc: 0.66062\tvalid_1's binary_logloss: 0.21786\n",
      "[173]\ttraining's auc: 0.711938\ttraining's binary_logloss: 0.214239\tvalid_1's auc: 0.660893\tvalid_1's binary_logloss: 0.217828\n",
      "[174]\ttraining's auc: 0.712252\ttraining's binary_logloss: 0.214189\tvalid_1's auc: 0.66112\tvalid_1's binary_logloss: 0.217798\n",
      "[175]\ttraining's auc: 0.712462\ttraining's binary_logloss: 0.214151\tvalid_1's auc: 0.661086\tvalid_1's binary_logloss: 0.217795\n",
      "[176]\ttraining's auc: 0.712748\ttraining's binary_logloss: 0.214101\tvalid_1's auc: 0.661237\tvalid_1's binary_logloss: 0.217775\n",
      "[177]\ttraining's auc: 0.712898\ttraining's binary_logloss: 0.214061\tvalid_1's auc: 0.661294\tvalid_1's binary_logloss: 0.217765\n",
      "[178]\ttraining's auc: 0.713079\ttraining's binary_logloss: 0.214025\tvalid_1's auc: 0.661337\tvalid_1's binary_logloss: 0.217758\n",
      "[179]\ttraining's auc: 0.713273\ttraining's binary_logloss: 0.213987\tvalid_1's auc: 0.661304\tvalid_1's binary_logloss: 0.217752\n",
      "[180]\ttraining's auc: 0.713505\ttraining's binary_logloss: 0.213951\tvalid_1's auc: 0.661283\tvalid_1's binary_logloss: 0.21775\n",
      "[181]\ttraining's auc: 0.71375\ttraining's binary_logloss: 0.213911\tvalid_1's auc: 0.661382\tvalid_1's binary_logloss: 0.217737\n",
      "[182]\ttraining's auc: 0.714047\ttraining's binary_logloss: 0.213861\tvalid_1's auc: 0.661571\tvalid_1's binary_logloss: 0.217712\n",
      "[183]\ttraining's auc: 0.714284\ttraining's binary_logloss: 0.213827\tvalid_1's auc: 0.661584\tvalid_1's binary_logloss: 0.217709\n",
      "[184]\ttraining's auc: 0.714525\ttraining's binary_logloss: 0.213787\tvalid_1's auc: 0.661718\tvalid_1's binary_logloss: 0.217692\n",
      "[185]\ttraining's auc: 0.714777\ttraining's binary_logloss: 0.213747\tvalid_1's auc: 0.661815\tvalid_1's binary_logloss: 0.217676\n",
      "[186]\ttraining's auc: 0.715045\ttraining's binary_logloss: 0.213705\tvalid_1's auc: 0.661888\tvalid_1's binary_logloss: 0.217667\n",
      "[187]\ttraining's auc: 0.715264\ttraining's binary_logloss: 0.21367\tvalid_1's auc: 0.66196\tvalid_1's binary_logloss: 0.217659\n",
      "[188]\ttraining's auc: 0.715504\ttraining's binary_logloss: 0.213627\tvalid_1's auc: 0.662061\tvalid_1's binary_logloss: 0.217645\n",
      "[189]\ttraining's auc: 0.71568\ttraining's binary_logloss: 0.213592\tvalid_1's auc: 0.662078\tvalid_1's binary_logloss: 0.217636\n",
      "[190]\ttraining's auc: 0.715848\ttraining's binary_logloss: 0.213555\tvalid_1's auc: 0.662079\tvalid_1's binary_logloss: 0.217631\n",
      "[191]\ttraining's auc: 0.716216\ttraining's binary_logloss: 0.213496\tvalid_1's auc: 0.662411\tvalid_1's binary_logloss: 0.217593\n",
      "[192]\ttraining's auc: 0.716505\ttraining's binary_logloss: 0.213444\tvalid_1's auc: 0.662636\tvalid_1's binary_logloss: 0.217563\n",
      "[193]\ttraining's auc: 0.716742\ttraining's binary_logloss: 0.213399\tvalid_1's auc: 0.662713\tvalid_1's binary_logloss: 0.217552\n",
      "[194]\ttraining's auc: 0.716947\ttraining's binary_logloss: 0.213354\tvalid_1's auc: 0.662896\tvalid_1's binary_logloss: 0.217529\n",
      "[195]\ttraining's auc: 0.71713\ttraining's binary_logloss: 0.213321\tvalid_1's auc: 0.662916\tvalid_1's binary_logloss: 0.21752\n",
      "[196]\ttraining's auc: 0.717287\ttraining's binary_logloss: 0.213291\tvalid_1's auc: 0.662844\tvalid_1's binary_logloss: 0.217522\n",
      "[197]\ttraining's auc: 0.717558\ttraining's binary_logloss: 0.213248\tvalid_1's auc: 0.663024\tvalid_1's binary_logloss: 0.217502\n",
      "[198]\ttraining's auc: 0.717782\ttraining's binary_logloss: 0.21321\tvalid_1's auc: 0.663189\tvalid_1's binary_logloss: 0.217484\n",
      "[199]\ttraining's auc: 0.717946\ttraining's binary_logloss: 0.213177\tvalid_1's auc: 0.663287\tvalid_1's binary_logloss: 0.217473\n",
      "[200]\ttraining's auc: 0.718114\ttraining's binary_logloss: 0.21314\tvalid_1's auc: 0.663329\tvalid_1's binary_logloss: 0.217464\n",
      "[201]\ttraining's auc: 0.718339\ttraining's binary_logloss: 0.213104\tvalid_1's auc: 0.663421\tvalid_1's binary_logloss: 0.217455\n",
      "[202]\ttraining's auc: 0.718522\ttraining's binary_logloss: 0.213072\tvalid_1's auc: 0.66335\tvalid_1's binary_logloss: 0.217459\n",
      "[203]\ttraining's auc: 0.718745\ttraining's binary_logloss: 0.213034\tvalid_1's auc: 0.663338\tvalid_1's binary_logloss: 0.21746\n",
      "[204]\ttraining's auc: 0.718973\ttraining's binary_logloss: 0.212996\tvalid_1's auc: 0.663385\tvalid_1's binary_logloss: 0.217452\n",
      "[205]\ttraining's auc: 0.719169\ttraining's binary_logloss: 0.212959\tvalid_1's auc: 0.663445\tvalid_1's binary_logloss: 0.217442\n",
      "[206]\ttraining's auc: 0.719376\ttraining's binary_logloss: 0.212928\tvalid_1's auc: 0.663424\tvalid_1's binary_logloss: 0.217444\n",
      "[207]\ttraining's auc: 0.719583\ttraining's binary_logloss: 0.212892\tvalid_1's auc: 0.663425\tvalid_1's binary_logloss: 0.21744\n",
      "[208]\ttraining's auc: 0.719773\ttraining's binary_logloss: 0.21286\tvalid_1's auc: 0.663406\tvalid_1's binary_logloss: 0.217438\n",
      "[209]\ttraining's auc: 0.719938\ttraining's binary_logloss: 0.212824\tvalid_1's auc: 0.663468\tvalid_1's binary_logloss: 0.217427\n",
      "[210]\ttraining's auc: 0.720104\ttraining's binary_logloss: 0.212791\tvalid_1's auc: 0.663545\tvalid_1's binary_logloss: 0.217417\n",
      "[211]\ttraining's auc: 0.720279\ttraining's binary_logloss: 0.212762\tvalid_1's auc: 0.663573\tvalid_1's binary_logloss: 0.21741\n",
      "[212]\ttraining's auc: 0.720423\ttraining's binary_logloss: 0.212733\tvalid_1's auc: 0.6636\tvalid_1's binary_logloss: 0.217404\n",
      "[213]\ttraining's auc: 0.720594\ttraining's binary_logloss: 0.2127\tvalid_1's auc: 0.663659\tvalid_1's binary_logloss: 0.217395\n",
      "[214]\ttraining's auc: 0.720749\ttraining's binary_logloss: 0.212666\tvalid_1's auc: 0.663726\tvalid_1's binary_logloss: 0.217386\n",
      "[215]\ttraining's auc: 0.720927\ttraining's binary_logloss: 0.212632\tvalid_1's auc: 0.663794\tvalid_1's binary_logloss: 0.217377\n",
      "[216]\ttraining's auc: 0.721099\ttraining's binary_logloss: 0.212596\tvalid_1's auc: 0.663835\tvalid_1's binary_logloss: 0.217367\n",
      "[217]\ttraining's auc: 0.721231\ttraining's binary_logloss: 0.212563\tvalid_1's auc: 0.663856\tvalid_1's binary_logloss: 0.21736\n",
      "[218]\ttraining's auc: 0.721393\ttraining's binary_logloss: 0.212526\tvalid_1's auc: 0.663942\tvalid_1's binary_logloss: 0.217349\n",
      "[219]\ttraining's auc: 0.721631\ttraining's binary_logloss: 0.212485\tvalid_1's auc: 0.664058\tvalid_1's binary_logloss: 0.217331\n",
      "[220]\ttraining's auc: 0.721879\ttraining's binary_logloss: 0.212446\tvalid_1's auc: 0.664224\tvalid_1's binary_logloss: 0.217313\n",
      "[221]\ttraining's auc: 0.722079\ttraining's binary_logloss: 0.212412\tvalid_1's auc: 0.664342\tvalid_1's binary_logloss: 0.217299\n",
      "[222]\ttraining's auc: 0.722289\ttraining's binary_logloss: 0.212378\tvalid_1's auc: 0.664374\tvalid_1's binary_logloss: 0.217294\n",
      "[223]\ttraining's auc: 0.722495\ttraining's binary_logloss: 0.212344\tvalid_1's auc: 0.664417\tvalid_1's binary_logloss: 0.217287\n",
      "[224]\ttraining's auc: 0.722668\ttraining's binary_logloss: 0.212314\tvalid_1's auc: 0.664423\tvalid_1's binary_logloss: 0.217283\n",
      "[225]\ttraining's auc: 0.72284\ttraining's binary_logloss: 0.212281\tvalid_1's auc: 0.664521\tvalid_1's binary_logloss: 0.217274\n",
      "[226]\ttraining's auc: 0.722999\ttraining's binary_logloss: 0.21225\tvalid_1's auc: 0.664603\tvalid_1's binary_logloss: 0.217264\n",
      "[227]\ttraining's auc: 0.723144\ttraining's binary_logloss: 0.212221\tvalid_1's auc: 0.66468\tvalid_1's binary_logloss: 0.217255\n",
      "[228]\ttraining's auc: 0.723323\ttraining's binary_logloss: 0.212189\tvalid_1's auc: 0.664728\tvalid_1's binary_logloss: 0.217251\n",
      "[229]\ttraining's auc: 0.72352\ttraining's binary_logloss: 0.212159\tvalid_1's auc: 0.664778\tvalid_1's binary_logloss: 0.217247\n",
      "[230]\ttraining's auc: 0.723713\ttraining's binary_logloss: 0.212125\tvalid_1's auc: 0.664875\tvalid_1's binary_logloss: 0.217233\n",
      "[231]\ttraining's auc: 0.723868\ttraining's binary_logloss: 0.212093\tvalid_1's auc: 0.664925\tvalid_1's binary_logloss: 0.217224\n",
      "[232]\ttraining's auc: 0.724062\ttraining's binary_logloss: 0.212057\tvalid_1's auc: 0.664967\tvalid_1's binary_logloss: 0.217215\n",
      "[233]\ttraining's auc: 0.724245\ttraining's binary_logloss: 0.212026\tvalid_1's auc: 0.664958\tvalid_1's binary_logloss: 0.217216\n",
      "[234]\ttraining's auc: 0.724433\ttraining's binary_logloss: 0.211998\tvalid_1's auc: 0.664887\tvalid_1's binary_logloss: 0.217218\n",
      "[235]\ttraining's auc: 0.724645\ttraining's binary_logloss: 0.211965\tvalid_1's auc: 0.664976\tvalid_1's binary_logloss: 0.217207\n",
      "[236]\ttraining's auc: 0.724849\ttraining's binary_logloss: 0.211934\tvalid_1's auc: 0.665039\tvalid_1's binary_logloss: 0.217196\n",
      "[237]\ttraining's auc: 0.725048\ttraining's binary_logloss: 0.211898\tvalid_1's auc: 0.665094\tvalid_1's binary_logloss: 0.21719\n",
      "[238]\ttraining's auc: 0.725214\ttraining's binary_logloss: 0.211866\tvalid_1's auc: 0.665098\tvalid_1's binary_logloss: 0.217188\n",
      "[239]\ttraining's auc: 0.725484\ttraining's binary_logloss: 0.211824\tvalid_1's auc: 0.665206\tvalid_1's binary_logloss: 0.217173\n",
      "[240]\ttraining's auc: 0.725791\ttraining's binary_logloss: 0.211778\tvalid_1's auc: 0.665296\tvalid_1's binary_logloss: 0.217158\n",
      "[241]\ttraining's auc: 0.726065\ttraining's binary_logloss: 0.21174\tvalid_1's auc: 0.665441\tvalid_1's binary_logloss: 0.217141\n",
      "[242]\ttraining's auc: 0.726243\ttraining's binary_logloss: 0.211707\tvalid_1's auc: 0.665511\tvalid_1's binary_logloss: 0.217129\n",
      "[243]\ttraining's auc: 0.726421\ttraining's binary_logloss: 0.211672\tvalid_1's auc: 0.665513\tvalid_1's binary_logloss: 0.217127\n",
      "[244]\ttraining's auc: 0.726641\ttraining's binary_logloss: 0.211638\tvalid_1's auc: 0.665592\tvalid_1's binary_logloss: 0.217116\n",
      "[245]\ttraining's auc: 0.726843\ttraining's binary_logloss: 0.211608\tvalid_1's auc: 0.665569\tvalid_1's binary_logloss: 0.217115\n",
      "[246]\ttraining's auc: 0.727033\ttraining's binary_logloss: 0.211578\tvalid_1's auc: 0.665533\tvalid_1's binary_logloss: 0.21711\n",
      "[247]\ttraining's auc: 0.727314\ttraining's binary_logloss: 0.211541\tvalid_1's auc: 0.665619\tvalid_1's binary_logloss: 0.217105\n",
      "[248]\ttraining's auc: 0.72756\ttraining's binary_logloss: 0.211508\tvalid_1's auc: 0.665648\tvalid_1's binary_logloss: 0.217101\n",
      "[249]\ttraining's auc: 0.727723\ttraining's binary_logloss: 0.211473\tvalid_1's auc: 0.665762\tvalid_1's binary_logloss: 0.217085\n",
      "[250]\ttraining's auc: 0.727884\ttraining's binary_logloss: 0.211439\tvalid_1's auc: 0.66578\tvalid_1's binary_logloss: 0.21708\n",
      "[251]\ttraining's auc: 0.728133\ttraining's binary_logloss: 0.211405\tvalid_1's auc: 0.665847\tvalid_1's binary_logloss: 0.217071\n",
      "[252]\ttraining's auc: 0.728326\ttraining's binary_logloss: 0.211373\tvalid_1's auc: 0.665959\tvalid_1's binary_logloss: 0.217061\n",
      "[253]\ttraining's auc: 0.728475\ttraining's binary_logloss: 0.211346\tvalid_1's auc: 0.665983\tvalid_1's binary_logloss: 0.217055\n",
      "[254]\ttraining's auc: 0.728588\ttraining's binary_logloss: 0.21132\tvalid_1's auc: 0.666072\tvalid_1's binary_logloss: 0.217042\n",
      "[255]\ttraining's auc: 0.728802\ttraining's binary_logloss: 0.211292\tvalid_1's auc: 0.666085\tvalid_1's binary_logloss: 0.217039\n",
      "[256]\ttraining's auc: 0.72901\ttraining's binary_logloss: 0.211266\tvalid_1's auc: 0.666135\tvalid_1's binary_logloss: 0.217032\n",
      "[257]\ttraining's auc: 0.729203\ttraining's binary_logloss: 0.211234\tvalid_1's auc: 0.666196\tvalid_1's binary_logloss: 0.217024\n",
      "[258]\ttraining's auc: 0.72936\ttraining's binary_logloss: 0.211207\tvalid_1's auc: 0.666256\tvalid_1's binary_logloss: 0.217015\n",
      "[259]\ttraining's auc: 0.729547\ttraining's binary_logloss: 0.211177\tvalid_1's auc: 0.666334\tvalid_1's binary_logloss: 0.21701\n",
      "[260]\ttraining's auc: 0.729678\ttraining's binary_logloss: 0.211154\tvalid_1's auc: 0.666342\tvalid_1's binary_logloss: 0.217011\n",
      "[261]\ttraining's auc: 0.729803\ttraining's binary_logloss: 0.21113\tvalid_1's auc: 0.666392\tvalid_1's binary_logloss: 0.217007\n",
      "[262]\ttraining's auc: 0.729878\ttraining's binary_logloss: 0.211111\tvalid_1's auc: 0.666395\tvalid_1's binary_logloss: 0.217005\n",
      "[263]\ttraining's auc: 0.73\ttraining's binary_logloss: 0.211089\tvalid_1's auc: 0.666476\tvalid_1's binary_logloss: 0.217\n",
      "[264]\ttraining's auc: 0.730155\ttraining's binary_logloss: 0.211062\tvalid_1's auc: 0.666559\tvalid_1's binary_logloss: 0.216996\n",
      "[265]\ttraining's auc: 0.730319\ttraining's binary_logloss: 0.211029\tvalid_1's auc: 0.666631\tvalid_1's binary_logloss: 0.216984\n",
      "[266]\ttraining's auc: 0.730484\ttraining's binary_logloss: 0.210998\tvalid_1's auc: 0.666713\tvalid_1's binary_logloss: 0.216971\n",
      "[267]\ttraining's auc: 0.730613\ttraining's binary_logloss: 0.210969\tvalid_1's auc: 0.666773\tvalid_1's binary_logloss: 0.21696\n",
      "[268]\ttraining's auc: 0.730763\ttraining's binary_logloss: 0.21094\tvalid_1's auc: 0.666842\tvalid_1's binary_logloss: 0.216948\n",
      "[269]\ttraining's auc: 0.730929\ttraining's binary_logloss: 0.210911\tvalid_1's auc: 0.666821\tvalid_1's binary_logloss: 0.216947\n",
      "[270]\ttraining's auc: 0.7311\ttraining's binary_logloss: 0.21088\tvalid_1's auc: 0.666792\tvalid_1's binary_logloss: 0.216946\n",
      "[271]\ttraining's auc: 0.731213\ttraining's binary_logloss: 0.210863\tvalid_1's auc: 0.666796\tvalid_1's binary_logloss: 0.216945\n",
      "[272]\ttraining's auc: 0.731406\ttraining's binary_logloss: 0.210833\tvalid_1's auc: 0.666946\tvalid_1's binary_logloss: 0.216929\n",
      "[273]\ttraining's auc: 0.731578\ttraining's binary_logloss: 0.210802\tvalid_1's auc: 0.666987\tvalid_1's binary_logloss: 0.216923\n",
      "[274]\ttraining's auc: 0.731729\ttraining's binary_logloss: 0.210774\tvalid_1's auc: 0.667013\tvalid_1's binary_logloss: 0.21692\n",
      "[275]\ttraining's auc: 0.731883\ttraining's binary_logloss: 0.210746\tvalid_1's auc: 0.667028\tvalid_1's binary_logloss: 0.216917\n",
      "[276]\ttraining's auc: 0.732044\ttraining's binary_logloss: 0.21072\tvalid_1's auc: 0.667044\tvalid_1's binary_logloss: 0.216912\n",
      "[277]\ttraining's auc: 0.732211\ttraining's binary_logloss: 0.210696\tvalid_1's auc: 0.667104\tvalid_1's binary_logloss: 0.216906\n",
      "[278]\ttraining's auc: 0.732313\ttraining's binary_logloss: 0.210678\tvalid_1's auc: 0.667148\tvalid_1's binary_logloss: 0.216902\n",
      "[279]\ttraining's auc: 0.732526\ttraining's binary_logloss: 0.210639\tvalid_1's auc: 0.667283\tvalid_1's binary_logloss: 0.216885\n",
      "[280]\ttraining's auc: 0.732649\ttraining's binary_logloss: 0.210613\tvalid_1's auc: 0.66737\tvalid_1's binary_logloss: 0.216871\n",
      "[281]\ttraining's auc: 0.73278\ttraining's binary_logloss: 0.210583\tvalid_1's auc: 0.667368\tvalid_1's binary_logloss: 0.216868\n",
      "[282]\ttraining's auc: 0.732987\ttraining's binary_logloss: 0.210551\tvalid_1's auc: 0.667342\tvalid_1's binary_logloss: 0.216868\n",
      "[283]\ttraining's auc: 0.73304\ttraining's binary_logloss: 0.210537\tvalid_1's auc: 0.667331\tvalid_1's binary_logloss: 0.216869\n",
      "[284]\ttraining's auc: 0.733165\ttraining's binary_logloss: 0.210512\tvalid_1's auc: 0.667352\tvalid_1's binary_logloss: 0.216866\n",
      "[285]\ttraining's auc: 0.733349\ttraining's binary_logloss: 0.21048\tvalid_1's auc: 0.667357\tvalid_1's binary_logloss: 0.21686\n",
      "[286]\ttraining's auc: 0.733504\ttraining's binary_logloss: 0.210452\tvalid_1's auc: 0.667335\tvalid_1's binary_logloss: 0.216857\n",
      "[287]\ttraining's auc: 0.733653\ttraining's binary_logloss: 0.210426\tvalid_1's auc: 0.667345\tvalid_1's binary_logloss: 0.216859\n",
      "[288]\ttraining's auc: 0.733861\ttraining's binary_logloss: 0.210397\tvalid_1's auc: 0.667407\tvalid_1's binary_logloss: 0.21685\n",
      "[289]\ttraining's auc: 0.73404\ttraining's binary_logloss: 0.210367\tvalid_1's auc: 0.667408\tvalid_1's binary_logloss: 0.216847\n",
      "[290]\ttraining's auc: 0.734262\ttraining's binary_logloss: 0.210326\tvalid_1's auc: 0.667562\tvalid_1's binary_logloss: 0.216825\n",
      "[291]\ttraining's auc: 0.734438\ttraining's binary_logloss: 0.210288\tvalid_1's auc: 0.667658\tvalid_1's binary_logloss: 0.216813\n",
      "[292]\ttraining's auc: 0.73462\ttraining's binary_logloss: 0.210254\tvalid_1's auc: 0.667795\tvalid_1's binary_logloss: 0.216795\n",
      "[293]\ttraining's auc: 0.734787\ttraining's binary_logloss: 0.210222\tvalid_1's auc: 0.667853\tvalid_1's binary_logloss: 0.216784\n",
      "[294]\ttraining's auc: 0.734998\ttraining's binary_logloss: 0.21018\tvalid_1's auc: 0.667943\tvalid_1's binary_logloss: 0.216767\n",
      "[295]\ttraining's auc: 0.735059\ttraining's binary_logloss: 0.210169\tvalid_1's auc: 0.667949\tvalid_1's binary_logloss: 0.216766\n",
      "[296]\ttraining's auc: 0.735243\ttraining's binary_logloss: 0.210142\tvalid_1's auc: 0.667977\tvalid_1's binary_logloss: 0.216763\n",
      "[297]\ttraining's auc: 0.735449\ttraining's binary_logloss: 0.210109\tvalid_1's auc: 0.668031\tvalid_1's binary_logloss: 0.216756\n",
      "[298]\ttraining's auc: 0.735659\ttraining's binary_logloss: 0.210077\tvalid_1's auc: 0.668079\tvalid_1's binary_logloss: 0.216749\n",
      "[299]\ttraining's auc: 0.735759\ttraining's binary_logloss: 0.210053\tvalid_1's auc: 0.668138\tvalid_1's binary_logloss: 0.216741\n",
      "[300]\ttraining's auc: 0.735907\ttraining's binary_logloss: 0.210022\tvalid_1's auc: 0.668185\tvalid_1's binary_logloss: 0.216734\n",
      "[301]\ttraining's auc: 0.736116\ttraining's binary_logloss: 0.209991\tvalid_1's auc: 0.668242\tvalid_1's binary_logloss: 0.216726\n",
      "[302]\ttraining's auc: 0.736292\ttraining's binary_logloss: 0.209963\tvalid_1's auc: 0.66824\tvalid_1's binary_logloss: 0.216721\n",
      "[303]\ttraining's auc: 0.73647\ttraining's binary_logloss: 0.20994\tvalid_1's auc: 0.668254\tvalid_1's binary_logloss: 0.216721\n",
      "[304]\ttraining's auc: 0.736636\ttraining's binary_logloss: 0.209915\tvalid_1's auc: 0.668257\tvalid_1's binary_logloss: 0.216721\n",
      "[305]\ttraining's auc: 0.736883\ttraining's binary_logloss: 0.209878\tvalid_1's auc: 0.668352\tvalid_1's binary_logloss: 0.216708\n",
      "[306]\ttraining's auc: 0.736988\ttraining's binary_logloss: 0.209859\tvalid_1's auc: 0.668387\tvalid_1's binary_logloss: 0.216702\n",
      "[307]\ttraining's auc: 0.737134\ttraining's binary_logloss: 0.209832\tvalid_1's auc: 0.668439\tvalid_1's binary_logloss: 0.216698\n",
      "[308]\ttraining's auc: 0.73733\ttraining's binary_logloss: 0.209793\tvalid_1's auc: 0.668606\tvalid_1's binary_logloss: 0.216681\n",
      "[309]\ttraining's auc: 0.737466\ttraining's binary_logloss: 0.209771\tvalid_1's auc: 0.668621\tvalid_1's binary_logloss: 0.216677\n",
      "[310]\ttraining's auc: 0.737607\ttraining's binary_logloss: 0.209747\tvalid_1's auc: 0.668639\tvalid_1's binary_logloss: 0.216672\n",
      "[311]\ttraining's auc: 0.737789\ttraining's binary_logloss: 0.209713\tvalid_1's auc: 0.668711\tvalid_1's binary_logloss: 0.216664\n",
      "[312]\ttraining's auc: 0.737904\ttraining's binary_logloss: 0.209683\tvalid_1's auc: 0.668847\tvalid_1's binary_logloss: 0.21665\n",
      "[313]\ttraining's auc: 0.738096\ttraining's binary_logloss: 0.209651\tvalid_1's auc: 0.668908\tvalid_1's binary_logloss: 0.216642\n",
      "[314]\ttraining's auc: 0.738239\ttraining's binary_logloss: 0.209615\tvalid_1's auc: 0.668943\tvalid_1's binary_logloss: 0.216634\n",
      "[315]\ttraining's auc: 0.738383\ttraining's binary_logloss: 0.209592\tvalid_1's auc: 0.668943\tvalid_1's binary_logloss: 0.216632\n",
      "[316]\ttraining's auc: 0.738527\ttraining's binary_logloss: 0.209566\tvalid_1's auc: 0.66896\tvalid_1's binary_logloss: 0.216628\n",
      "[317]\ttraining's auc: 0.738658\ttraining's binary_logloss: 0.209537\tvalid_1's auc: 0.669017\tvalid_1's binary_logloss: 0.21662\n",
      "[318]\ttraining's auc: 0.73884\ttraining's binary_logloss: 0.209502\tvalid_1's auc: 0.669173\tvalid_1's binary_logloss: 0.216599\n",
      "[319]\ttraining's auc: 0.739073\ttraining's binary_logloss: 0.209471\tvalid_1's auc: 0.669251\tvalid_1's binary_logloss: 0.216588\n",
      "[320]\ttraining's auc: 0.739238\ttraining's binary_logloss: 0.20944\tvalid_1's auc: 0.669395\tvalid_1's binary_logloss: 0.216571\n",
      "[321]\ttraining's auc: 0.739495\ttraining's binary_logloss: 0.2094\tvalid_1's auc: 0.669518\tvalid_1's binary_logloss: 0.216557\n",
      "[322]\ttraining's auc: 0.739736\ttraining's binary_logloss: 0.209361\tvalid_1's auc: 0.669676\tvalid_1's binary_logloss: 0.216539\n",
      "[323]\ttraining's auc: 0.739878\ttraining's binary_logloss: 0.209336\tvalid_1's auc: 0.669739\tvalid_1's binary_logloss: 0.216533\n",
      "[324]\ttraining's auc: 0.740013\ttraining's binary_logloss: 0.209312\tvalid_1's auc: 0.669765\tvalid_1's binary_logloss: 0.216531\n",
      "[325]\ttraining's auc: 0.740164\ttraining's binary_logloss: 0.209286\tvalid_1's auc: 0.669782\tvalid_1's binary_logloss: 0.216528\n",
      "[326]\ttraining's auc: 0.740306\ttraining's binary_logloss: 0.20926\tvalid_1's auc: 0.669757\tvalid_1's binary_logloss: 0.216527\n",
      "[327]\ttraining's auc: 0.740476\ttraining's binary_logloss: 0.209234\tvalid_1's auc: 0.669753\tvalid_1's binary_logloss: 0.216525\n",
      "[328]\ttraining's auc: 0.740651\ttraining's binary_logloss: 0.209204\tvalid_1's auc: 0.66983\tvalid_1's binary_logloss: 0.216516\n",
      "[329]\ttraining's auc: 0.740813\ttraining's binary_logloss: 0.209176\tvalid_1's auc: 0.669877\tvalid_1's binary_logloss: 0.216509\n",
      "[330]\ttraining's auc: 0.741008\ttraining's binary_logloss: 0.209147\tvalid_1's auc: 0.669921\tvalid_1's binary_logloss: 0.216502\n",
      "[331]\ttraining's auc: 0.741194\ttraining's binary_logloss: 0.20912\tvalid_1's auc: 0.669945\tvalid_1's binary_logloss: 0.216501\n",
      "[332]\ttraining's auc: 0.741328\ttraining's binary_logloss: 0.209094\tvalid_1's auc: 0.669961\tvalid_1's binary_logloss: 0.216496\n",
      "[333]\ttraining's auc: 0.741547\ttraining's binary_logloss: 0.209062\tvalid_1's auc: 0.670044\tvalid_1's binary_logloss: 0.216487\n",
      "[334]\ttraining's auc: 0.741742\ttraining's binary_logloss: 0.20903\tvalid_1's auc: 0.670113\tvalid_1's binary_logloss: 0.216481\n",
      "[335]\ttraining's auc: 0.741962\ttraining's binary_logloss: 0.208999\tvalid_1's auc: 0.670146\tvalid_1's binary_logloss: 0.216474\n",
      "[336]\ttraining's auc: 0.742091\ttraining's binary_logloss: 0.208969\tvalid_1's auc: 0.670211\tvalid_1's binary_logloss: 0.216463\n",
      "[337]\ttraining's auc: 0.742229\ttraining's binary_logloss: 0.208942\tvalid_1's auc: 0.670225\tvalid_1's binary_logloss: 0.216461\n",
      "[338]\ttraining's auc: 0.742404\ttraining's binary_logloss: 0.208916\tvalid_1's auc: 0.670237\tvalid_1's binary_logloss: 0.216461\n",
      "[339]\ttraining's auc: 0.742577\ttraining's binary_logloss: 0.208892\tvalid_1's auc: 0.670214\tvalid_1's binary_logloss: 0.216461\n",
      "[340]\ttraining's auc: 0.742693\ttraining's binary_logloss: 0.208871\tvalid_1's auc: 0.670188\tvalid_1's binary_logloss: 0.216462\n",
      "[341]\ttraining's auc: 0.742748\ttraining's binary_logloss: 0.208858\tvalid_1's auc: 0.670219\tvalid_1's binary_logloss: 0.216458\n",
      "[342]\ttraining's auc: 0.742927\ttraining's binary_logloss: 0.208831\tvalid_1's auc: 0.670288\tvalid_1's binary_logloss: 0.216451\n",
      "[343]\ttraining's auc: 0.74306\ttraining's binary_logloss: 0.208809\tvalid_1's auc: 0.67032\tvalid_1's binary_logloss: 0.216446\n",
      "[344]\ttraining's auc: 0.743174\ttraining's binary_logloss: 0.208789\tvalid_1's auc: 0.670383\tvalid_1's binary_logloss: 0.216438\n",
      "[345]\ttraining's auc: 0.74342\ttraining's binary_logloss: 0.208754\tvalid_1's auc: 0.670387\tvalid_1's binary_logloss: 0.216441\n",
      "[346]\ttraining's auc: 0.743618\ttraining's binary_logloss: 0.20872\tvalid_1's auc: 0.670558\tvalid_1's binary_logloss: 0.216421\n",
      "[347]\ttraining's auc: 0.743767\ttraining's binary_logloss: 0.208696\tvalid_1's auc: 0.670584\tvalid_1's binary_logloss: 0.216419\n",
      "[348]\ttraining's auc: 0.74394\ttraining's binary_logloss: 0.208668\tvalid_1's auc: 0.670607\tvalid_1's binary_logloss: 0.216414\n",
      "[349]\ttraining's auc: 0.744095\ttraining's binary_logloss: 0.208637\tvalid_1's auc: 0.670592\tvalid_1's binary_logloss: 0.216415\n",
      "[350]\ttraining's auc: 0.744273\ttraining's binary_logloss: 0.208608\tvalid_1's auc: 0.670583\tvalid_1's binary_logloss: 0.216414\n",
      "[351]\ttraining's auc: 0.744428\ttraining's binary_logloss: 0.208576\tvalid_1's auc: 0.670667\tvalid_1's binary_logloss: 0.216404\n",
      "[352]\ttraining's auc: 0.744553\ttraining's binary_logloss: 0.208547\tvalid_1's auc: 0.670762\tvalid_1's binary_logloss: 0.216391\n",
      "[353]\ttraining's auc: 0.744686\ttraining's binary_logloss: 0.208524\tvalid_1's auc: 0.670774\tvalid_1's binary_logloss: 0.216389\n",
      "[354]\ttraining's auc: 0.744785\ttraining's binary_logloss: 0.208502\tvalid_1's auc: 0.670764\tvalid_1's binary_logloss: 0.216393\n",
      "[355]\ttraining's auc: 0.744941\ttraining's binary_logloss: 0.208473\tvalid_1's auc: 0.670838\tvalid_1's binary_logloss: 0.216387\n",
      "[356]\ttraining's auc: 0.745083\ttraining's binary_logloss: 0.208447\tvalid_1's auc: 0.670857\tvalid_1's binary_logloss: 0.216383\n",
      "[357]\ttraining's auc: 0.745238\ttraining's binary_logloss: 0.208423\tvalid_1's auc: 0.670817\tvalid_1's binary_logloss: 0.216383\n",
      "[358]\ttraining's auc: 0.745371\ttraining's binary_logloss: 0.2084\tvalid_1's auc: 0.670826\tvalid_1's binary_logloss: 0.21638\n",
      "[359]\ttraining's auc: 0.745529\ttraining's binary_logloss: 0.208374\tvalid_1's auc: 0.670817\tvalid_1's binary_logloss: 0.216379\n",
      "[360]\ttraining's auc: 0.745676\ttraining's binary_logloss: 0.208346\tvalid_1's auc: 0.670768\tvalid_1's binary_logloss: 0.216384\n",
      "[361]\ttraining's auc: 0.745849\ttraining's binary_logloss: 0.208319\tvalid_1's auc: 0.670807\tvalid_1's binary_logloss: 0.216377\n",
      "[362]\ttraining's auc: 0.745991\ttraining's binary_logloss: 0.208295\tvalid_1's auc: 0.670824\tvalid_1's binary_logloss: 0.216378\n",
      "[363]\ttraining's auc: 0.746161\ttraining's binary_logloss: 0.208267\tvalid_1's auc: 0.670865\tvalid_1's binary_logloss: 0.216374\n",
      "[364]\ttraining's auc: 0.746263\ttraining's binary_logloss: 0.208239\tvalid_1's auc: 0.670892\tvalid_1's binary_logloss: 0.216369\n",
      "[365]\ttraining's auc: 0.746432\ttraining's binary_logloss: 0.208208\tvalid_1's auc: 0.670963\tvalid_1's binary_logloss: 0.216358\n",
      "[366]\ttraining's auc: 0.746607\ttraining's binary_logloss: 0.208177\tvalid_1's auc: 0.670986\tvalid_1's binary_logloss: 0.216352\n",
      "[367]\ttraining's auc: 0.746787\ttraining's binary_logloss: 0.208152\tvalid_1's auc: 0.670995\tvalid_1's binary_logloss: 0.216351\n",
      "[368]\ttraining's auc: 0.746931\ttraining's binary_logloss: 0.208123\tvalid_1's auc: 0.671034\tvalid_1's binary_logloss: 0.216347\n",
      "[369]\ttraining's auc: 0.74708\ttraining's binary_logloss: 0.208094\tvalid_1's auc: 0.671083\tvalid_1's binary_logloss: 0.216341\n",
      "[370]\ttraining's auc: 0.747295\ttraining's binary_logloss: 0.208067\tvalid_1's auc: 0.671098\tvalid_1's binary_logloss: 0.216338\n",
      "[371]\ttraining's auc: 0.74744\ttraining's binary_logloss: 0.208041\tvalid_1's auc: 0.671151\tvalid_1's binary_logloss: 0.21633\n",
      "[372]\ttraining's auc: 0.74758\ttraining's binary_logloss: 0.208014\tvalid_1's auc: 0.671146\tvalid_1's binary_logloss: 0.21633\n",
      "[373]\ttraining's auc: 0.74768\ttraining's binary_logloss: 0.207995\tvalid_1's auc: 0.671124\tvalid_1's binary_logloss: 0.216333\n",
      "[374]\ttraining's auc: 0.747775\ttraining's binary_logloss: 0.207978\tvalid_1's auc: 0.671113\tvalid_1's binary_logloss: 0.216332\n",
      "[375]\ttraining's auc: 0.747893\ttraining's binary_logloss: 0.207953\tvalid_1's auc: 0.671141\tvalid_1's binary_logloss: 0.216327\n",
      "[376]\ttraining's auc: 0.747983\ttraining's binary_logloss: 0.20793\tvalid_1's auc: 0.671191\tvalid_1's binary_logloss: 0.216322\n",
      "[377]\ttraining's auc: 0.748095\ttraining's binary_logloss: 0.207903\tvalid_1's auc: 0.671207\tvalid_1's binary_logloss: 0.216317\n",
      "[378]\ttraining's auc: 0.748267\ttraining's binary_logloss: 0.207875\tvalid_1's auc: 0.671277\tvalid_1's binary_logloss: 0.216311\n",
      "[379]\ttraining's auc: 0.748416\ttraining's binary_logloss: 0.207852\tvalid_1's auc: 0.671347\tvalid_1's binary_logloss: 0.216305\n",
      "[380]\ttraining's auc: 0.748593\ttraining's binary_logloss: 0.207827\tvalid_1's auc: 0.671324\tvalid_1's binary_logloss: 0.21631\n",
      "[381]\ttraining's auc: 0.748783\ttraining's binary_logloss: 0.2078\tvalid_1's auc: 0.671324\tvalid_1's binary_logloss: 0.216311\n",
      "[382]\ttraining's auc: 0.748926\ttraining's binary_logloss: 0.207771\tvalid_1's auc: 0.671417\tvalid_1's binary_logloss: 0.216298\n",
      "[383]\ttraining's auc: 0.749123\ttraining's binary_logloss: 0.207745\tvalid_1's auc: 0.6714\tvalid_1's binary_logloss: 0.2163\n",
      "[384]\ttraining's auc: 0.749275\ttraining's binary_logloss: 0.207721\tvalid_1's auc: 0.671428\tvalid_1's binary_logloss: 0.216296\n",
      "[385]\ttraining's auc: 0.74948\ttraining's binary_logloss: 0.207689\tvalid_1's auc: 0.671531\tvalid_1's binary_logloss: 0.21628\n",
      "[386]\ttraining's auc: 0.749659\ttraining's binary_logloss: 0.207661\tvalid_1's auc: 0.671585\tvalid_1's binary_logloss: 0.21627\n",
      "[387]\ttraining's auc: 0.749867\ttraining's binary_logloss: 0.207633\tvalid_1's auc: 0.671619\tvalid_1's binary_logloss: 0.216266\n",
      "[388]\ttraining's auc: 0.750051\ttraining's binary_logloss: 0.207607\tvalid_1's auc: 0.671618\tvalid_1's binary_logloss: 0.216267\n",
      "[389]\ttraining's auc: 0.750109\ttraining's binary_logloss: 0.207595\tvalid_1's auc: 0.671614\tvalid_1's binary_logloss: 0.216266\n",
      "[390]\ttraining's auc: 0.75025\ttraining's binary_logloss: 0.207571\tvalid_1's auc: 0.67161\tvalid_1's binary_logloss: 0.216267\n",
      "[391]\ttraining's auc: 0.75038\ttraining's binary_logloss: 0.207546\tvalid_1's auc: 0.671644\tvalid_1's binary_logloss: 0.216263\n",
      "[392]\ttraining's auc: 0.750539\ttraining's binary_logloss: 0.207519\tvalid_1's auc: 0.67166\tvalid_1's binary_logloss: 0.216262\n",
      "[393]\ttraining's auc: 0.75064\ttraining's binary_logloss: 0.207499\tvalid_1's auc: 0.671676\tvalid_1's binary_logloss: 0.216258\n",
      "[394]\ttraining's auc: 0.750714\ttraining's binary_logloss: 0.207486\tvalid_1's auc: 0.671696\tvalid_1's binary_logloss: 0.216255\n",
      "[395]\ttraining's auc: 0.750818\ttraining's binary_logloss: 0.207462\tvalid_1's auc: 0.671702\tvalid_1's binary_logloss: 0.216255\n",
      "[396]\ttraining's auc: 0.75092\ttraining's binary_logloss: 0.207437\tvalid_1's auc: 0.671719\tvalid_1's binary_logloss: 0.216256\n",
      "[397]\ttraining's auc: 0.75111\ttraining's binary_logloss: 0.207406\tvalid_1's auc: 0.671766\tvalid_1's binary_logloss: 0.216249\n",
      "[398]\ttraining's auc: 0.751267\ttraining's binary_logloss: 0.207379\tvalid_1's auc: 0.671781\tvalid_1's binary_logloss: 0.216243\n",
      "[399]\ttraining's auc: 0.751423\ttraining's binary_logloss: 0.207354\tvalid_1's auc: 0.671828\tvalid_1's binary_logloss: 0.216238\n",
      "[400]\ttraining's auc: 0.751567\ttraining's binary_logloss: 0.20733\tvalid_1's auc: 0.671816\tvalid_1's binary_logloss: 0.216238\n",
      "[401]\ttraining's auc: 0.751596\ttraining's binary_logloss: 0.207318\tvalid_1's auc: 0.671826\tvalid_1's binary_logloss: 0.216239\n",
      "[402]\ttraining's auc: 0.751657\ttraining's binary_logloss: 0.207302\tvalid_1's auc: 0.671857\tvalid_1's binary_logloss: 0.216236\n",
      "[403]\ttraining's auc: 0.751816\ttraining's binary_logloss: 0.207275\tvalid_1's auc: 0.671876\tvalid_1's binary_logloss: 0.216234\n",
      "[404]\ttraining's auc: 0.751944\ttraining's binary_logloss: 0.207255\tvalid_1's auc: 0.671944\tvalid_1's binary_logloss: 0.216228\n",
      "[405]\ttraining's auc: 0.752112\ttraining's binary_logloss: 0.207231\tvalid_1's auc: 0.671957\tvalid_1's binary_logloss: 0.216227\n",
      "[406]\ttraining's auc: 0.752244\ttraining's binary_logloss: 0.207209\tvalid_1's auc: 0.671927\tvalid_1's binary_logloss: 0.216229\n",
      "[407]\ttraining's auc: 0.752392\ttraining's binary_logloss: 0.207185\tvalid_1's auc: 0.67189\tvalid_1's binary_logloss: 0.21623\n",
      "[408]\ttraining's auc: 0.75253\ttraining's binary_logloss: 0.207159\tvalid_1's auc: 0.671906\tvalid_1's binary_logloss: 0.216229\n",
      "[409]\ttraining's auc: 0.752588\ttraining's binary_logloss: 0.20715\tvalid_1's auc: 0.671901\tvalid_1's binary_logloss: 0.216234\n",
      "[410]\ttraining's auc: 0.752686\ttraining's binary_logloss: 0.207132\tvalid_1's auc: 0.671929\tvalid_1's binary_logloss: 0.216231\n",
      "[411]\ttraining's auc: 0.752827\ttraining's binary_logloss: 0.207109\tvalid_1's auc: 0.671954\tvalid_1's binary_logloss: 0.216229\n",
      "[412]\ttraining's auc: 0.75297\ttraining's binary_logloss: 0.207086\tvalid_1's auc: 0.671959\tvalid_1's binary_logloss: 0.216229\n",
      "[413]\ttraining's auc: 0.753083\ttraining's binary_logloss: 0.207063\tvalid_1's auc: 0.671975\tvalid_1's binary_logloss: 0.216226\n",
      "[414]\ttraining's auc: 0.753235\ttraining's binary_logloss: 0.207039\tvalid_1's auc: 0.672016\tvalid_1's binary_logloss: 0.21622\n",
      "[415]\ttraining's auc: 0.75339\ttraining's binary_logloss: 0.207015\tvalid_1's auc: 0.672017\tvalid_1's binary_logloss: 0.216221\n",
      "[416]\ttraining's auc: 0.753521\ttraining's binary_logloss: 0.206994\tvalid_1's auc: 0.672021\tvalid_1's binary_logloss: 0.21622\n",
      "[417]\ttraining's auc: 0.753628\ttraining's binary_logloss: 0.206971\tvalid_1's auc: 0.672055\tvalid_1's binary_logloss: 0.216219\n",
      "[418]\ttraining's auc: 0.753686\ttraining's binary_logloss: 0.206957\tvalid_1's auc: 0.672045\tvalid_1's binary_logloss: 0.216219\n",
      "[419]\ttraining's auc: 0.753856\ttraining's binary_logloss: 0.206933\tvalid_1's auc: 0.672053\tvalid_1's binary_logloss: 0.216218\n",
      "[420]\ttraining's auc: 0.753919\ttraining's binary_logloss: 0.206917\tvalid_1's auc: 0.672096\tvalid_1's binary_logloss: 0.216211\n",
      "[421]\ttraining's auc: 0.75404\ttraining's binary_logloss: 0.206892\tvalid_1's auc: 0.672087\tvalid_1's binary_logloss: 0.216211\n",
      "[422]\ttraining's auc: 0.754169\ttraining's binary_logloss: 0.206869\tvalid_1's auc: 0.672123\tvalid_1's binary_logloss: 0.216208\n",
      "[423]\ttraining's auc: 0.754316\ttraining's binary_logloss: 0.206843\tvalid_1's auc: 0.672104\tvalid_1's binary_logloss: 0.21621\n",
      "[424]\ttraining's auc: 0.754477\ttraining's binary_logloss: 0.206816\tvalid_1's auc: 0.672153\tvalid_1's binary_logloss: 0.216205\n",
      "[425]\ttraining's auc: 0.754517\ttraining's binary_logloss: 0.206806\tvalid_1's auc: 0.672177\tvalid_1's binary_logloss: 0.216204\n",
      "[426]\ttraining's auc: 0.754528\ttraining's binary_logloss: 0.2068\tvalid_1's auc: 0.672197\tvalid_1's binary_logloss: 0.216202\n",
      "[427]\ttraining's auc: 0.754696\ttraining's binary_logloss: 0.206774\tvalid_1's auc: 0.672181\tvalid_1's binary_logloss: 0.216205\n",
      "[428]\ttraining's auc: 0.75485\ttraining's binary_logloss: 0.206746\tvalid_1's auc: 0.672176\tvalid_1's binary_logloss: 0.216207\n",
      "[429]\ttraining's auc: 0.754991\ttraining's binary_logloss: 0.20672\tvalid_1's auc: 0.672268\tvalid_1's binary_logloss: 0.216197\n",
      "[430]\ttraining's auc: 0.755118\ttraining's binary_logloss: 0.206692\tvalid_1's auc: 0.672355\tvalid_1's binary_logloss: 0.216183\n",
      "[431]\ttraining's auc: 0.755229\ttraining's binary_logloss: 0.206668\tvalid_1's auc: 0.672397\tvalid_1's binary_logloss: 0.216176\n",
      "[432]\ttraining's auc: 0.75536\ttraining's binary_logloss: 0.206639\tvalid_1's auc: 0.672445\tvalid_1's binary_logloss: 0.216171\n",
      "[433]\ttraining's auc: 0.755461\ttraining's binary_logloss: 0.206621\tvalid_1's auc: 0.672462\tvalid_1's binary_logloss: 0.216169\n",
      "[434]\ttraining's auc: 0.755557\ttraining's binary_logloss: 0.2066\tvalid_1's auc: 0.672451\tvalid_1's binary_logloss: 0.21617\n",
      "[435]\ttraining's auc: 0.755666\ttraining's binary_logloss: 0.206579\tvalid_1's auc: 0.672431\tvalid_1's binary_logloss: 0.216171\n",
      "[436]\ttraining's auc: 0.755721\ttraining's binary_logloss: 0.206566\tvalid_1's auc: 0.672454\tvalid_1's binary_logloss: 0.216167\n",
      "[437]\ttraining's auc: 0.75589\ttraining's binary_logloss: 0.20654\tvalid_1's auc: 0.672478\tvalid_1's binary_logloss: 0.216165\n",
      "[438]\ttraining's auc: 0.756021\ttraining's binary_logloss: 0.20651\tvalid_1's auc: 0.672569\tvalid_1's binary_logloss: 0.216151\n",
      "[439]\ttraining's auc: 0.756147\ttraining's binary_logloss: 0.206484\tvalid_1's auc: 0.67265\tvalid_1's binary_logloss: 0.216142\n",
      "[440]\ttraining's auc: 0.756334\ttraining's binary_logloss: 0.206453\tvalid_1's auc: 0.672777\tvalid_1's binary_logloss: 0.216126\n",
      "[441]\ttraining's auc: 0.756481\ttraining's binary_logloss: 0.206429\tvalid_1's auc: 0.672795\tvalid_1's binary_logloss: 0.216127\n",
      "[442]\ttraining's auc: 0.756618\ttraining's binary_logloss: 0.206401\tvalid_1's auc: 0.672799\tvalid_1's binary_logloss: 0.216128\n",
      "[443]\ttraining's auc: 0.756732\ttraining's binary_logloss: 0.206381\tvalid_1's auc: 0.672796\tvalid_1's binary_logloss: 0.216128\n",
      "[444]\ttraining's auc: 0.756866\ttraining's binary_logloss: 0.20636\tvalid_1's auc: 0.672821\tvalid_1's binary_logloss: 0.216126\n",
      "[445]\ttraining's auc: 0.756988\ttraining's binary_logloss: 0.206338\tvalid_1's auc: 0.67281\tvalid_1's binary_logloss: 0.216127\n",
      "[446]\ttraining's auc: 0.757083\ttraining's binary_logloss: 0.206315\tvalid_1's auc: 0.672861\tvalid_1's binary_logloss: 0.216121\n",
      "[447]\ttraining's auc: 0.75719\ttraining's binary_logloss: 0.206293\tvalid_1's auc: 0.672889\tvalid_1's binary_logloss: 0.216116\n",
      "[448]\ttraining's auc: 0.757338\ttraining's binary_logloss: 0.206267\tvalid_1's auc: 0.672921\tvalid_1's binary_logloss: 0.216112\n",
      "[449]\ttraining's auc: 0.757422\ttraining's binary_logloss: 0.206245\tvalid_1's auc: 0.672934\tvalid_1's binary_logloss: 0.216108\n",
      "[450]\ttraining's auc: 0.757518\ttraining's binary_logloss: 0.206223\tvalid_1's auc: 0.672962\tvalid_1's binary_logloss: 0.216103\n",
      "[451]\ttraining's auc: 0.757628\ttraining's binary_logloss: 0.206201\tvalid_1's auc: 0.672956\tvalid_1's binary_logloss: 0.216105\n",
      "[452]\ttraining's auc: 0.757736\ttraining's binary_logloss: 0.206179\tvalid_1's auc: 0.672931\tvalid_1's binary_logloss: 0.216109\n",
      "[453]\ttraining's auc: 0.757917\ttraining's binary_logloss: 0.206151\tvalid_1's auc: 0.672997\tvalid_1's binary_logloss: 0.216101\n",
      "[454]\ttraining's auc: 0.758061\ttraining's binary_logloss: 0.206125\tvalid_1's auc: 0.673067\tvalid_1's binary_logloss: 0.216093\n",
      "[455]\ttraining's auc: 0.758242\ttraining's binary_logloss: 0.206096\tvalid_1's auc: 0.673136\tvalid_1's binary_logloss: 0.216088\n",
      "[456]\ttraining's auc: 0.758395\ttraining's binary_logloss: 0.206067\tvalid_1's auc: 0.67321\tvalid_1's binary_logloss: 0.216081\n",
      "[457]\ttraining's auc: 0.758472\ttraining's binary_logloss: 0.206045\tvalid_1's auc: 0.673245\tvalid_1's binary_logloss: 0.216075\n",
      "[458]\ttraining's auc: 0.758537\ttraining's binary_logloss: 0.206029\tvalid_1's auc: 0.673261\tvalid_1's binary_logloss: 0.216073\n",
      "[459]\ttraining's auc: 0.758617\ttraining's binary_logloss: 0.206013\tvalid_1's auc: 0.673281\tvalid_1's binary_logloss: 0.216071\n",
      "[460]\ttraining's auc: 0.758698\ttraining's binary_logloss: 0.205996\tvalid_1's auc: 0.673253\tvalid_1's binary_logloss: 0.216073\n",
      "[461]\ttraining's auc: 0.758878\ttraining's binary_logloss: 0.205969\tvalid_1's auc: 0.673266\tvalid_1's binary_logloss: 0.216071\n",
      "[462]\ttraining's auc: 0.759039\ttraining's binary_logloss: 0.205943\tvalid_1's auc: 0.673318\tvalid_1's binary_logloss: 0.216063\n",
      "[463]\ttraining's auc: 0.759212\ttraining's binary_logloss: 0.205915\tvalid_1's auc: 0.673383\tvalid_1's binary_logloss: 0.216053\n",
      "[464]\ttraining's auc: 0.759359\ttraining's binary_logloss: 0.205889\tvalid_1's auc: 0.673448\tvalid_1's binary_logloss: 0.216043\n",
      "[465]\ttraining's auc: 0.75948\ttraining's binary_logloss: 0.205869\tvalid_1's auc: 0.673455\tvalid_1's binary_logloss: 0.216041\n",
      "[466]\ttraining's auc: 0.759631\ttraining's binary_logloss: 0.205846\tvalid_1's auc: 0.673432\tvalid_1's binary_logloss: 0.216045\n",
      "[467]\ttraining's auc: 0.759753\ttraining's binary_logloss: 0.205821\tvalid_1's auc: 0.673459\tvalid_1's binary_logloss: 0.216042\n",
      "[468]\ttraining's auc: 0.759869\ttraining's binary_logloss: 0.205795\tvalid_1's auc: 0.673532\tvalid_1's binary_logloss: 0.21603\n",
      "[469]\ttraining's auc: 0.760038\ttraining's binary_logloss: 0.205767\tvalid_1's auc: 0.673586\tvalid_1's binary_logloss: 0.216024\n",
      "[470]\ttraining's auc: 0.760212\ttraining's binary_logloss: 0.205741\tvalid_1's auc: 0.673626\tvalid_1's binary_logloss: 0.216017\n",
      "[471]\ttraining's auc: 0.760319\ttraining's binary_logloss: 0.205721\tvalid_1's auc: 0.673633\tvalid_1's binary_logloss: 0.216018\n",
      "[472]\ttraining's auc: 0.760383\ttraining's binary_logloss: 0.205709\tvalid_1's auc: 0.673652\tvalid_1's binary_logloss: 0.216016\n",
      "[473]\ttraining's auc: 0.760494\ttraining's binary_logloss: 0.205684\tvalid_1's auc: 0.673697\tvalid_1's binary_logloss: 0.216009\n",
      "[474]\ttraining's auc: 0.760625\ttraining's binary_logloss: 0.205659\tvalid_1's auc: 0.673715\tvalid_1's binary_logloss: 0.216005\n",
      "[475]\ttraining's auc: 0.760765\ttraining's binary_logloss: 0.205636\tvalid_1's auc: 0.673725\tvalid_1's binary_logloss: 0.216005\n",
      "[476]\ttraining's auc: 0.760892\ttraining's binary_logloss: 0.205613\tvalid_1's auc: 0.67373\tvalid_1's binary_logloss: 0.216004\n",
      "[477]\ttraining's auc: 0.761041\ttraining's binary_logloss: 0.205589\tvalid_1's auc: 0.673701\tvalid_1's binary_logloss: 0.216004\n",
      "[478]\ttraining's auc: 0.761168\ttraining's binary_logloss: 0.205566\tvalid_1's auc: 0.673697\tvalid_1's binary_logloss: 0.216004\n",
      "[479]\ttraining's auc: 0.761296\ttraining's binary_logloss: 0.205539\tvalid_1's auc: 0.67374\tvalid_1's binary_logloss: 0.215997\n",
      "[480]\ttraining's auc: 0.761433\ttraining's binary_logloss: 0.20551\tvalid_1's auc: 0.673753\tvalid_1's binary_logloss: 0.215997\n",
      "[481]\ttraining's auc: 0.761592\ttraining's binary_logloss: 0.205483\tvalid_1's auc: 0.673816\tvalid_1's binary_logloss: 0.215992\n",
      "[482]\ttraining's auc: 0.76171\ttraining's binary_logloss: 0.20546\tvalid_1's auc: 0.673871\tvalid_1's binary_logloss: 0.215986\n",
      "[483]\ttraining's auc: 0.761847\ttraining's binary_logloss: 0.205433\tvalid_1's auc: 0.673913\tvalid_1's binary_logloss: 0.215981\n",
      "[484]\ttraining's auc: 0.762042\ttraining's binary_logloss: 0.205401\tvalid_1's auc: 0.673912\tvalid_1's binary_logloss: 0.21598\n",
      "[485]\ttraining's auc: 0.762189\ttraining's binary_logloss: 0.205373\tvalid_1's auc: 0.673886\tvalid_1's binary_logloss: 0.215982\n",
      "[486]\ttraining's auc: 0.762307\ttraining's binary_logloss: 0.205351\tvalid_1's auc: 0.673896\tvalid_1's binary_logloss: 0.215978\n",
      "[487]\ttraining's auc: 0.762478\ttraining's binary_logloss: 0.205327\tvalid_1's auc: 0.673934\tvalid_1's binary_logloss: 0.215973\n",
      "[488]\ttraining's auc: 0.762605\ttraining's binary_logloss: 0.205305\tvalid_1's auc: 0.67397\tvalid_1's binary_logloss: 0.215969\n",
      "[489]\ttraining's auc: 0.762757\ttraining's binary_logloss: 0.205279\tvalid_1's auc: 0.673965\tvalid_1's binary_logloss: 0.215971\n",
      "[490]\ttraining's auc: 0.762893\ttraining's binary_logloss: 0.205256\tvalid_1's auc: 0.673981\tvalid_1's binary_logloss: 0.21597\n",
      "[491]\ttraining's auc: 0.763034\ttraining's binary_logloss: 0.205227\tvalid_1's auc: 0.674075\tvalid_1's binary_logloss: 0.215959\n",
      "[492]\ttraining's auc: 0.763162\ttraining's binary_logloss: 0.205201\tvalid_1's auc: 0.674141\tvalid_1's binary_logloss: 0.215954\n",
      "[493]\ttraining's auc: 0.763236\ttraining's binary_logloss: 0.205188\tvalid_1's auc: 0.67412\tvalid_1's binary_logloss: 0.215957\n",
      "[494]\ttraining's auc: 0.763359\ttraining's binary_logloss: 0.205164\tvalid_1's auc: 0.674141\tvalid_1's binary_logloss: 0.215956\n",
      "[495]\ttraining's auc: 0.763419\ttraining's binary_logloss: 0.20515\tvalid_1's auc: 0.674148\tvalid_1's binary_logloss: 0.215953\n",
      "[496]\ttraining's auc: 0.763531\ttraining's binary_logloss: 0.205127\tvalid_1's auc: 0.674161\tvalid_1's binary_logloss: 0.215951\n",
      "[497]\ttraining's auc: 0.763672\ttraining's binary_logloss: 0.205101\tvalid_1's auc: 0.674146\tvalid_1's binary_logloss: 0.21595\n",
      "[498]\ttraining's auc: 0.763811\ttraining's binary_logloss: 0.205077\tvalid_1's auc: 0.674149\tvalid_1's binary_logloss: 0.215951\n",
      "[499]\ttraining's auc: 0.763994\ttraining's binary_logloss: 0.205046\tvalid_1's auc: 0.674164\tvalid_1's binary_logloss: 0.21595\n",
      "[500]\ttraining's auc: 0.764096\ttraining's binary_logloss: 0.205023\tvalid_1's auc: 0.674196\tvalid_1's binary_logloss: 0.215948\n",
      "[501]\ttraining's auc: 0.764215\ttraining's binary_logloss: 0.205001\tvalid_1's auc: 0.674194\tvalid_1's binary_logloss: 0.215947\n",
      "[502]\ttraining's auc: 0.764355\ttraining's binary_logloss: 0.204977\tvalid_1's auc: 0.674174\tvalid_1's binary_logloss: 0.215947\n",
      "[503]\ttraining's auc: 0.764412\ttraining's binary_logloss: 0.204959\tvalid_1's auc: 0.674203\tvalid_1's binary_logloss: 0.215944\n",
      "[504]\ttraining's auc: 0.764511\ttraining's binary_logloss: 0.204937\tvalid_1's auc: 0.674218\tvalid_1's binary_logloss: 0.215944\n",
      "[505]\ttraining's auc: 0.764647\ttraining's binary_logloss: 0.204914\tvalid_1's auc: 0.67428\tvalid_1's binary_logloss: 0.215939\n",
      "[506]\ttraining's auc: 0.764854\ttraining's binary_logloss: 0.204885\tvalid_1's auc: 0.674303\tvalid_1's binary_logloss: 0.215938\n",
      "[507]\ttraining's auc: 0.764998\ttraining's binary_logloss: 0.20486\tvalid_1's auc: 0.674338\tvalid_1's binary_logloss: 0.215931\n",
      "[508]\ttraining's auc: 0.765075\ttraining's binary_logloss: 0.204837\tvalid_1's auc: 0.674395\tvalid_1's binary_logloss: 0.215925\n",
      "[509]\ttraining's auc: 0.765174\ttraining's binary_logloss: 0.204817\tvalid_1's auc: 0.674411\tvalid_1's binary_logloss: 0.215923\n",
      "[510]\ttraining's auc: 0.765254\ttraining's binary_logloss: 0.204801\tvalid_1's auc: 0.674436\tvalid_1's binary_logloss: 0.215922\n",
      "[511]\ttraining's auc: 0.76537\ttraining's binary_logloss: 0.204779\tvalid_1's auc: 0.674453\tvalid_1's binary_logloss: 0.215919\n",
      "[512]\ttraining's auc: 0.765469\ttraining's binary_logloss: 0.204756\tvalid_1's auc: 0.674541\tvalid_1's binary_logloss: 0.215907\n",
      "[513]\ttraining's auc: 0.765593\ttraining's binary_logloss: 0.204732\tvalid_1's auc: 0.674522\tvalid_1's binary_logloss: 0.215907\n",
      "[514]\ttraining's auc: 0.76572\ttraining's binary_logloss: 0.204709\tvalid_1's auc: 0.674563\tvalid_1's binary_logloss: 0.215902\n",
      "[515]\ttraining's auc: 0.765832\ttraining's binary_logloss: 0.204682\tvalid_1's auc: 0.674549\tvalid_1's binary_logloss: 0.215905\n",
      "[516]\ttraining's auc: 0.765929\ttraining's binary_logloss: 0.204657\tvalid_1's auc: 0.674552\tvalid_1's binary_logloss: 0.215907\n",
      "[517]\ttraining's auc: 0.765973\ttraining's binary_logloss: 0.20464\tvalid_1's auc: 0.67455\tvalid_1's binary_logloss: 0.215907\n",
      "[518]\ttraining's auc: 0.766057\ttraining's binary_logloss: 0.204619\tvalid_1's auc: 0.674527\tvalid_1's binary_logloss: 0.215909\n",
      "[519]\ttraining's auc: 0.766212\ttraining's binary_logloss: 0.204597\tvalid_1's auc: 0.674526\tvalid_1's binary_logloss: 0.215909\n",
      "[520]\ttraining's auc: 0.766361\ttraining's binary_logloss: 0.204577\tvalid_1's auc: 0.674592\tvalid_1's binary_logloss: 0.215904\n",
      "[521]\ttraining's auc: 0.7665\ttraining's binary_logloss: 0.204553\tvalid_1's auc: 0.674575\tvalid_1's binary_logloss: 0.215902\n",
      "[522]\ttraining's auc: 0.766613\ttraining's binary_logloss: 0.204529\tvalid_1's auc: 0.674571\tvalid_1's binary_logloss: 0.2159\n",
      "[523]\ttraining's auc: 0.766754\ttraining's binary_logloss: 0.204506\tvalid_1's auc: 0.674554\tvalid_1's binary_logloss: 0.215901\n",
      "[524]\ttraining's auc: 0.766876\ttraining's binary_logloss: 0.204486\tvalid_1's auc: 0.674546\tvalid_1's binary_logloss: 0.215901\n",
      "[525]\ttraining's auc: 0.767023\ttraining's binary_logloss: 0.204464\tvalid_1's auc: 0.674574\tvalid_1's binary_logloss: 0.215899\n",
      "[526]\ttraining's auc: 0.767151\ttraining's binary_logloss: 0.204443\tvalid_1's auc: 0.674629\tvalid_1's binary_logloss: 0.215895\n",
      "[527]\ttraining's auc: 0.767284\ttraining's binary_logloss: 0.20442\tvalid_1's auc: 0.674608\tvalid_1's binary_logloss: 0.215898\n",
      "[528]\ttraining's auc: 0.767463\ttraining's binary_logloss: 0.204393\tvalid_1's auc: 0.674645\tvalid_1's binary_logloss: 0.215897\n",
      "[529]\ttraining's auc: 0.767569\ttraining's binary_logloss: 0.204373\tvalid_1's auc: 0.674628\tvalid_1's binary_logloss: 0.215898\n",
      "[530]\ttraining's auc: 0.767686\ttraining's binary_logloss: 0.204349\tvalid_1's auc: 0.674614\tvalid_1's binary_logloss: 0.215901\n",
      "[531]\ttraining's auc: 0.767841\ttraining's binary_logloss: 0.204326\tvalid_1's auc: 0.674593\tvalid_1's binary_logloss: 0.2159\n",
      "[532]\ttraining's auc: 0.767982\ttraining's binary_logloss: 0.204304\tvalid_1's auc: 0.674582\tvalid_1's binary_logloss: 0.2159\n",
      "[533]\ttraining's auc: 0.768086\ttraining's binary_logloss: 0.204285\tvalid_1's auc: 0.674588\tvalid_1's binary_logloss: 0.215898\n",
      "[534]\ttraining's auc: 0.768163\ttraining's binary_logloss: 0.204264\tvalid_1's auc: 0.674567\tvalid_1's binary_logloss: 0.215898\n",
      "[535]\ttraining's auc: 0.768291\ttraining's binary_logloss: 0.20424\tvalid_1's auc: 0.67458\tvalid_1's binary_logloss: 0.215898\n",
      "[536]\ttraining's auc: 0.768368\ttraining's binary_logloss: 0.204221\tvalid_1's auc: 0.674583\tvalid_1's binary_logloss: 0.215898\n",
      "[537]\ttraining's auc: 0.768439\ttraining's binary_logloss: 0.204206\tvalid_1's auc: 0.674631\tvalid_1's binary_logloss: 0.215891\n",
      "[538]\ttraining's auc: 0.768561\ttraining's binary_logloss: 0.204182\tvalid_1's auc: 0.674583\tvalid_1's binary_logloss: 0.215895\n",
      "[539]\ttraining's auc: 0.768644\ttraining's binary_logloss: 0.20416\tvalid_1's auc: 0.674595\tvalid_1's binary_logloss: 0.215893\n",
      "[540]\ttraining's auc: 0.768728\ttraining's binary_logloss: 0.20414\tvalid_1's auc: 0.674588\tvalid_1's binary_logloss: 0.215893\n",
      "[541]\ttraining's auc: 0.768837\ttraining's binary_logloss: 0.204118\tvalid_1's auc: 0.674582\tvalid_1's binary_logloss: 0.215892\n",
      "[542]\ttraining's auc: 0.768937\ttraining's binary_logloss: 0.204096\tvalid_1's auc: 0.674607\tvalid_1's binary_logloss: 0.215889\n",
      "[543]\ttraining's auc: 0.769039\ttraining's binary_logloss: 0.204077\tvalid_1's auc: 0.6746\tvalid_1's binary_logloss: 0.215889\n",
      "[544]\ttraining's auc: 0.769158\ttraining's binary_logloss: 0.204054\tvalid_1's auc: 0.674606\tvalid_1's binary_logloss: 0.215889\n",
      "[545]\ttraining's auc: 0.769294\ttraining's binary_logloss: 0.204032\tvalid_1's auc: 0.674608\tvalid_1's binary_logloss: 0.21589\n",
      "[546]\ttraining's auc: 0.769435\ttraining's binary_logloss: 0.204013\tvalid_1's auc: 0.674602\tvalid_1's binary_logloss: 0.21589\n",
      "[547]\ttraining's auc: 0.769574\ttraining's binary_logloss: 0.203988\tvalid_1's auc: 0.674625\tvalid_1's binary_logloss: 0.215886\n",
      "[548]\ttraining's auc: 0.769728\ttraining's binary_logloss: 0.203963\tvalid_1's auc: 0.674615\tvalid_1's binary_logloss: 0.215885\n",
      "[549]\ttraining's auc: 0.769826\ttraining's binary_logloss: 0.203946\tvalid_1's auc: 0.674654\tvalid_1's binary_logloss: 0.21588\n",
      "[550]\ttraining's auc: 0.769938\ttraining's binary_logloss: 0.203926\tvalid_1's auc: 0.674707\tvalid_1's binary_logloss: 0.215874\n",
      "[551]\ttraining's auc: 0.770029\ttraining's binary_logloss: 0.203904\tvalid_1's auc: 0.674752\tvalid_1's binary_logloss: 0.215868\n",
      "[552]\ttraining's auc: 0.770126\ttraining's binary_logloss: 0.203883\tvalid_1's auc: 0.674786\tvalid_1's binary_logloss: 0.215861\n",
      "[553]\ttraining's auc: 0.770274\ttraining's binary_logloss: 0.203858\tvalid_1's auc: 0.674757\tvalid_1's binary_logloss: 0.215864\n",
      "[554]\ttraining's auc: 0.770412\ttraining's binary_logloss: 0.203835\tvalid_1's auc: 0.674728\tvalid_1's binary_logloss: 0.215868\n",
      "[555]\ttraining's auc: 0.770554\ttraining's binary_logloss: 0.203812\tvalid_1's auc: 0.674727\tvalid_1's binary_logloss: 0.215867\n",
      "[556]\ttraining's auc: 0.770701\ttraining's binary_logloss: 0.203788\tvalid_1's auc: 0.674738\tvalid_1's binary_logloss: 0.215867\n",
      "[557]\ttraining's auc: 0.770816\ttraining's binary_logloss: 0.203768\tvalid_1's auc: 0.674778\tvalid_1's binary_logloss: 0.215863\n",
      "[558]\ttraining's auc: 0.7709\ttraining's binary_logloss: 0.203749\tvalid_1's auc: 0.674756\tvalid_1's binary_logloss: 0.215865\n",
      "[559]\ttraining's auc: 0.771035\ttraining's binary_logloss: 0.203721\tvalid_1's auc: 0.674807\tvalid_1's binary_logloss: 0.215858\n",
      "[560]\ttraining's auc: 0.771101\ttraining's binary_logloss: 0.203706\tvalid_1's auc: 0.674788\tvalid_1's binary_logloss: 0.215861\n",
      "[561]\ttraining's auc: 0.771215\ttraining's binary_logloss: 0.203682\tvalid_1's auc: 0.674807\tvalid_1's binary_logloss: 0.215858\n",
      "[562]\ttraining's auc: 0.771326\ttraining's binary_logloss: 0.203658\tvalid_1's auc: 0.674806\tvalid_1's binary_logloss: 0.215857\n",
      "[563]\ttraining's auc: 0.771426\ttraining's binary_logloss: 0.203638\tvalid_1's auc: 0.674817\tvalid_1's binary_logloss: 0.215856\n",
      "[564]\ttraining's auc: 0.771546\ttraining's binary_logloss: 0.203616\tvalid_1's auc: 0.674808\tvalid_1's binary_logloss: 0.215854\n",
      "[565]\ttraining's auc: 0.771726\ttraining's binary_logloss: 0.203593\tvalid_1's auc: 0.67482\tvalid_1's binary_logloss: 0.215855\n",
      "[566]\ttraining's auc: 0.771876\ttraining's binary_logloss: 0.203569\tvalid_1's auc: 0.67483\tvalid_1's binary_logloss: 0.215854\n",
      "[567]\ttraining's auc: 0.771957\ttraining's binary_logloss: 0.203551\tvalid_1's auc: 0.674813\tvalid_1's binary_logloss: 0.215856\n",
      "[568]\ttraining's auc: 0.771992\ttraining's binary_logloss: 0.203541\tvalid_1's auc: 0.674816\tvalid_1's binary_logloss: 0.215857\n",
      "[569]\ttraining's auc: 0.772127\ttraining's binary_logloss: 0.203518\tvalid_1's auc: 0.674805\tvalid_1's binary_logloss: 0.215859\n",
      "[570]\ttraining's auc: 0.772269\ttraining's binary_logloss: 0.203494\tvalid_1's auc: 0.674799\tvalid_1's binary_logloss: 0.21586\n",
      "[571]\ttraining's auc: 0.772392\ttraining's binary_logloss: 0.203472\tvalid_1's auc: 0.67487\tvalid_1's binary_logloss: 0.215854\n",
      "[572]\ttraining's auc: 0.772493\ttraining's binary_logloss: 0.203453\tvalid_1's auc: 0.674902\tvalid_1's binary_logloss: 0.21585\n",
      "[573]\ttraining's auc: 0.772595\ttraining's binary_logloss: 0.203436\tvalid_1's auc: 0.674898\tvalid_1's binary_logloss: 0.215854\n",
      "[574]\ttraining's auc: 0.77273\ttraining's binary_logloss: 0.203414\tvalid_1's auc: 0.674914\tvalid_1's binary_logloss: 0.215854\n",
      "[575]\ttraining's auc: 0.772831\ttraining's binary_logloss: 0.203393\tvalid_1's auc: 0.674964\tvalid_1's binary_logloss: 0.215849\n",
      "[576]\ttraining's auc: 0.772897\ttraining's binary_logloss: 0.203378\tvalid_1's auc: 0.674968\tvalid_1's binary_logloss: 0.215847\n",
      "[577]\ttraining's auc: 0.772982\ttraining's binary_logloss: 0.203364\tvalid_1's auc: 0.674977\tvalid_1's binary_logloss: 0.215845\n",
      "[578]\ttraining's auc: 0.773116\ttraining's binary_logloss: 0.203344\tvalid_1's auc: 0.674949\tvalid_1's binary_logloss: 0.21585\n",
      "[579]\ttraining's auc: 0.773231\ttraining's binary_logloss: 0.203321\tvalid_1's auc: 0.67491\tvalid_1's binary_logloss: 0.215856\n",
      "[580]\ttraining's auc: 0.773305\ttraining's binary_logloss: 0.203301\tvalid_1's auc: 0.674915\tvalid_1's binary_logloss: 0.215853\n",
      "[581]\ttraining's auc: 0.773315\ttraining's binary_logloss: 0.203299\tvalid_1's auc: 0.674915\tvalid_1's binary_logloss: 0.215853\n",
      "[582]\ttraining's auc: 0.773327\ttraining's binary_logloss: 0.203297\tvalid_1's auc: 0.674917\tvalid_1's binary_logloss: 0.215853\n",
      "[583]\ttraining's auc: 0.773457\ttraining's binary_logloss: 0.20327\tvalid_1's auc: 0.67496\tvalid_1's binary_logloss: 0.215848\n",
      "[584]\ttraining's auc: 0.773562\ttraining's binary_logloss: 0.203245\tvalid_1's auc: 0.674988\tvalid_1's binary_logloss: 0.215843\n",
      "[585]\ttraining's auc: 0.773681\ttraining's binary_logloss: 0.203222\tvalid_1's auc: 0.67498\tvalid_1's binary_logloss: 0.215844\n",
      "[586]\ttraining's auc: 0.773819\ttraining's binary_logloss: 0.203198\tvalid_1's auc: 0.675005\tvalid_1's binary_logloss: 0.215846\n",
      "[587]\ttraining's auc: 0.773922\ttraining's binary_logloss: 0.203181\tvalid_1's auc: 0.674989\tvalid_1's binary_logloss: 0.215847\n",
      "[588]\ttraining's auc: 0.774\ttraining's binary_logloss: 0.203166\tvalid_1's auc: 0.674995\tvalid_1's binary_logloss: 0.215846\n",
      "[589]\ttraining's auc: 0.774163\ttraining's binary_logloss: 0.203142\tvalid_1's auc: 0.674948\tvalid_1's binary_logloss: 0.215849\n",
      "[590]\ttraining's auc: 0.774301\ttraining's binary_logloss: 0.203118\tvalid_1's auc: 0.674976\tvalid_1's binary_logloss: 0.215846\n",
      "[591]\ttraining's auc: 0.774449\ttraining's binary_logloss: 0.203098\tvalid_1's auc: 0.674928\tvalid_1's binary_logloss: 0.215851\n",
      "[592]\ttraining's auc: 0.774573\ttraining's binary_logloss: 0.20308\tvalid_1's auc: 0.674943\tvalid_1's binary_logloss: 0.21585\n",
      "[593]\ttraining's auc: 0.774695\ttraining's binary_logloss: 0.203055\tvalid_1's auc: 0.674922\tvalid_1's binary_logloss: 0.215851\n",
      "[594]\ttraining's auc: 0.774836\ttraining's binary_logloss: 0.203032\tvalid_1's auc: 0.674892\tvalid_1's binary_logloss: 0.215855\n",
      "[595]\ttraining's auc: 0.774968\ttraining's binary_logloss: 0.203009\tvalid_1's auc: 0.674876\tvalid_1's binary_logloss: 0.215857\n",
      "[596]\ttraining's auc: 0.775095\ttraining's binary_logloss: 0.202987\tvalid_1's auc: 0.674843\tvalid_1's binary_logloss: 0.21586\n",
      "[597]\ttraining's auc: 0.775219\ttraining's binary_logloss: 0.202964\tvalid_1's auc: 0.674808\tvalid_1's binary_logloss: 0.215865\n",
      "[598]\ttraining's auc: 0.775321\ttraining's binary_logloss: 0.202942\tvalid_1's auc: 0.674809\tvalid_1's binary_logloss: 0.215867\n",
      "[599]\ttraining's auc: 0.775435\ttraining's binary_logloss: 0.20292\tvalid_1's auc: 0.674782\tvalid_1's binary_logloss: 0.215868\n",
      "[600]\ttraining's auc: 0.775545\ttraining's binary_logloss: 0.2029\tvalid_1's auc: 0.674773\tvalid_1's binary_logloss: 0.21587\n",
      "[601]\ttraining's auc: 0.775693\ttraining's binary_logloss: 0.202878\tvalid_1's auc: 0.674756\tvalid_1's binary_logloss: 0.215871\n",
      "[602]\ttraining's auc: 0.775838\ttraining's binary_logloss: 0.202855\tvalid_1's auc: 0.674755\tvalid_1's binary_logloss: 0.215871\n",
      "[603]\ttraining's auc: 0.775949\ttraining's binary_logloss: 0.202833\tvalid_1's auc: 0.674733\tvalid_1's binary_logloss: 0.215874\n",
      "[604]\ttraining's auc: 0.776043\ttraining's binary_logloss: 0.202812\tvalid_1's auc: 0.674697\tvalid_1's binary_logloss: 0.215879\n",
      "[605]\ttraining's auc: 0.776162\ttraining's binary_logloss: 0.20279\tvalid_1's auc: 0.674765\tvalid_1's binary_logloss: 0.215874\n",
      "[606]\ttraining's auc: 0.776182\ttraining's binary_logloss: 0.202784\tvalid_1's auc: 0.674756\tvalid_1's binary_logloss: 0.215874\n",
      "[607]\ttraining's auc: 0.776329\ttraining's binary_logloss: 0.202761\tvalid_1's auc: 0.674763\tvalid_1's binary_logloss: 0.215873\n",
      "[608]\ttraining's auc: 0.776441\ttraining's binary_logloss: 0.202736\tvalid_1's auc: 0.674759\tvalid_1's binary_logloss: 0.215874\n",
      "[609]\ttraining's auc: 0.776542\ttraining's binary_logloss: 0.202715\tvalid_1's auc: 0.674755\tvalid_1's binary_logloss: 0.215878\n",
      "[610]\ttraining's auc: 0.776647\ttraining's binary_logloss: 0.202695\tvalid_1's auc: 0.674757\tvalid_1's binary_logloss: 0.215879\n",
      "[611]\ttraining's auc: 0.776786\ttraining's binary_logloss: 0.202673\tvalid_1's auc: 0.674793\tvalid_1's binary_logloss: 0.215874\n",
      "[612]\ttraining's auc: 0.776898\ttraining's binary_logloss: 0.202654\tvalid_1's auc: 0.674773\tvalid_1's binary_logloss: 0.215876\n",
      "[613]\ttraining's auc: 0.776975\ttraining's binary_logloss: 0.202633\tvalid_1's auc: 0.674791\tvalid_1's binary_logloss: 0.215871\n",
      "[614]\ttraining's auc: 0.777054\ttraining's binary_logloss: 0.202612\tvalid_1's auc: 0.674819\tvalid_1's binary_logloss: 0.215866\n",
      "[615]\ttraining's auc: 0.777151\ttraining's binary_logloss: 0.202591\tvalid_1's auc: 0.674819\tvalid_1's binary_logloss: 0.215865\n",
      "[616]\ttraining's auc: 0.777257\ttraining's binary_logloss: 0.202568\tvalid_1's auc: 0.674844\tvalid_1's binary_logloss: 0.215862\n",
      "[617]\ttraining's auc: 0.77734\ttraining's binary_logloss: 0.202545\tvalid_1's auc: 0.674851\tvalid_1's binary_logloss: 0.21586\n",
      "[618]\ttraining's auc: 0.777404\ttraining's binary_logloss: 0.202526\tvalid_1's auc: 0.674837\tvalid_1's binary_logloss: 0.215862\n",
      "[619]\ttraining's auc: 0.777524\ttraining's binary_logloss: 0.202504\tvalid_1's auc: 0.674831\tvalid_1's binary_logloss: 0.215863\n",
      "[620]\ttraining's auc: 0.777646\ttraining's binary_logloss: 0.202484\tvalid_1's auc: 0.674831\tvalid_1's binary_logloss: 0.215865\n",
      "[621]\ttraining's auc: 0.777767\ttraining's binary_logloss: 0.202463\tvalid_1's auc: 0.674804\tvalid_1's binary_logloss: 0.215869\n",
      "[622]\ttraining's auc: 0.77787\ttraining's binary_logloss: 0.202445\tvalid_1's auc: 0.674784\tvalid_1's binary_logloss: 0.215871\n",
      "[623]\ttraining's auc: 0.777973\ttraining's binary_logloss: 0.202424\tvalid_1's auc: 0.674792\tvalid_1's binary_logloss: 0.215868\n",
      "[624]\ttraining's auc: 0.778054\ttraining's binary_logloss: 0.202402\tvalid_1's auc: 0.674831\tvalid_1's binary_logloss: 0.215865\n",
      "[625]\ttraining's auc: 0.7781\ttraining's binary_logloss: 0.202391\tvalid_1's auc: 0.674838\tvalid_1's binary_logloss: 0.215864\n",
      "[626]\ttraining's auc: 0.778147\ttraining's binary_logloss: 0.20238\tvalid_1's auc: 0.674846\tvalid_1's binary_logloss: 0.215862\n",
      "[627]\ttraining's auc: 0.778234\ttraining's binary_logloss: 0.202362\tvalid_1's auc: 0.674829\tvalid_1's binary_logloss: 0.215865\n",
      "[628]\ttraining's auc: 0.778341\ttraining's binary_logloss: 0.202339\tvalid_1's auc: 0.6748\tvalid_1's binary_logloss: 0.215871\n",
      "[629]\ttraining's auc: 0.77846\ttraining's binary_logloss: 0.202318\tvalid_1's auc: 0.674797\tvalid_1's binary_logloss: 0.215875\n",
      "[630]\ttraining's auc: 0.778558\ttraining's binary_logloss: 0.202298\tvalid_1's auc: 0.674822\tvalid_1's binary_logloss: 0.215871\n",
      "[631]\ttraining's auc: 0.77865\ttraining's binary_logloss: 0.202278\tvalid_1's auc: 0.674853\tvalid_1's binary_logloss: 0.215868\n",
      "[632]\ttraining's auc: 0.778734\ttraining's binary_logloss: 0.20226\tvalid_1's auc: 0.674867\tvalid_1's binary_logloss: 0.215867\n",
      "[633]\ttraining's auc: 0.778812\ttraining's binary_logloss: 0.202241\tvalid_1's auc: 0.674857\tvalid_1's binary_logloss: 0.215865\n",
      "[634]\ttraining's auc: 0.778823\ttraining's binary_logloss: 0.202235\tvalid_1's auc: 0.674848\tvalid_1's binary_logloss: 0.215867\n",
      "[635]\ttraining's auc: 0.778935\ttraining's binary_logloss: 0.202211\tvalid_1's auc: 0.674889\tvalid_1's binary_logloss: 0.215861\n",
      "[636]\ttraining's auc: 0.779068\ttraining's binary_logloss: 0.202188\tvalid_1's auc: 0.674943\tvalid_1's binary_logloss: 0.215856\n",
      "[637]\ttraining's auc: 0.779139\ttraining's binary_logloss: 0.202173\tvalid_1's auc: 0.674924\tvalid_1's binary_logloss: 0.215857\n",
      "[638]\ttraining's auc: 0.779196\ttraining's binary_logloss: 0.20216\tvalid_1's auc: 0.674938\tvalid_1's binary_logloss: 0.215856\n",
      "[639]\ttraining's auc: 0.77934\ttraining's binary_logloss: 0.202136\tvalid_1's auc: 0.674895\tvalid_1's binary_logloss: 0.21586\n",
      "[640]\ttraining's auc: 0.779434\ttraining's binary_logloss: 0.202113\tvalid_1's auc: 0.674852\tvalid_1's binary_logloss: 0.215865\n",
      "[641]\ttraining's auc: 0.779539\ttraining's binary_logloss: 0.20209\tvalid_1's auc: 0.67484\tvalid_1's binary_logloss: 0.215866\n",
      "[642]\ttraining's auc: 0.779613\ttraining's binary_logloss: 0.202073\tvalid_1's auc: 0.67483\tvalid_1's binary_logloss: 0.215868\n",
      "[643]\ttraining's auc: 0.779731\ttraining's binary_logloss: 0.202048\tvalid_1's auc: 0.67483\tvalid_1's binary_logloss: 0.215869\n",
      "[644]\ttraining's auc: 0.779854\ttraining's binary_logloss: 0.202025\tvalid_1's auc: 0.674844\tvalid_1's binary_logloss: 0.215865\n",
      "[645]\ttraining's auc: 0.779952\ttraining's binary_logloss: 0.202002\tvalid_1's auc: 0.67489\tvalid_1's binary_logloss: 0.21586\n",
      "[646]\ttraining's auc: 0.780096\ttraining's binary_logloss: 0.201978\tvalid_1's auc: 0.67489\tvalid_1's binary_logloss: 0.215862\n",
      "[647]\ttraining's auc: 0.780222\ttraining's binary_logloss: 0.201958\tvalid_1's auc: 0.674869\tvalid_1's binary_logloss: 0.215863\n",
      "[648]\ttraining's auc: 0.780339\ttraining's binary_logloss: 0.20194\tvalid_1's auc: 0.674895\tvalid_1's binary_logloss: 0.21586\n",
      "[649]\ttraining's auc: 0.780438\ttraining's binary_logloss: 0.201918\tvalid_1's auc: 0.674908\tvalid_1's binary_logloss: 0.215859\n",
      "[650]\ttraining's auc: 0.780554\ttraining's binary_logloss: 0.201895\tvalid_1's auc: 0.674914\tvalid_1's binary_logloss: 0.21586\n",
      "[651]\ttraining's auc: 0.780583\ttraining's binary_logloss: 0.201887\tvalid_1's auc: 0.674922\tvalid_1's binary_logloss: 0.215861\n",
      "[652]\ttraining's auc: 0.780608\ttraining's binary_logloss: 0.201881\tvalid_1's auc: 0.674936\tvalid_1's binary_logloss: 0.21586\n",
      "[653]\ttraining's auc: 0.780723\ttraining's binary_logloss: 0.201861\tvalid_1's auc: 0.674941\tvalid_1's binary_logloss: 0.215858\n",
      "[654]\ttraining's auc: 0.780829\ttraining's binary_logloss: 0.201839\tvalid_1's auc: 0.674965\tvalid_1's binary_logloss: 0.215857\n",
      "[655]\ttraining's auc: 0.780954\ttraining's binary_logloss: 0.201814\tvalid_1's auc: 0.674938\tvalid_1's binary_logloss: 0.215861\n",
      "[656]\ttraining's auc: 0.78106\ttraining's binary_logloss: 0.201794\tvalid_1's auc: 0.674925\tvalid_1's binary_logloss: 0.215861\n",
      "[657]\ttraining's auc: 0.781107\ttraining's binary_logloss: 0.201783\tvalid_1's auc: 0.674937\tvalid_1's binary_logloss: 0.215862\n",
      "[658]\ttraining's auc: 0.781163\ttraining's binary_logloss: 0.20177\tvalid_1's auc: 0.674939\tvalid_1's binary_logloss: 0.215861\n",
      "[659]\ttraining's auc: 0.781255\ttraining's binary_logloss: 0.201749\tvalid_1's auc: 0.674937\tvalid_1's binary_logloss: 0.215863\n",
      "[660]\ttraining's auc: 0.781336\ttraining's binary_logloss: 0.201732\tvalid_1's auc: 0.674949\tvalid_1's binary_logloss: 0.215861\n",
      "[661]\ttraining's auc: 0.781356\ttraining's binary_logloss: 0.201726\tvalid_1's auc: 0.674969\tvalid_1's binary_logloss: 0.215859\n",
      "[662]\ttraining's auc: 0.781373\ttraining's binary_logloss: 0.201719\tvalid_1's auc: 0.674983\tvalid_1's binary_logloss: 0.215858\n",
      "[663]\ttraining's auc: 0.781471\ttraining's binary_logloss: 0.2017\tvalid_1's auc: 0.674992\tvalid_1's binary_logloss: 0.215856\n",
      "[664]\ttraining's auc: 0.781568\ttraining's binary_logloss: 0.201682\tvalid_1's auc: 0.674993\tvalid_1's binary_logloss: 0.215856\n",
      "[665]\ttraining's auc: 0.781679\ttraining's binary_logloss: 0.201659\tvalid_1's auc: 0.674996\tvalid_1's binary_logloss: 0.215856\n",
      "[666]\ttraining's auc: 0.781753\ttraining's binary_logloss: 0.20164\tvalid_1's auc: 0.674959\tvalid_1's binary_logloss: 0.21586\n",
      "[667]\ttraining's auc: 0.781801\ttraining's binary_logloss: 0.201626\tvalid_1's auc: 0.674989\tvalid_1's binary_logloss: 0.215857\n",
      "[668]\ttraining's auc: 0.781906\ttraining's binary_logloss: 0.201605\tvalid_1's auc: 0.675015\tvalid_1's binary_logloss: 0.215855\n",
      "[669]\ttraining's auc: 0.782001\ttraining's binary_logloss: 0.201583\tvalid_1's auc: 0.675032\tvalid_1's binary_logloss: 0.215855\n",
      "[670]\ttraining's auc: 0.782074\ttraining's binary_logloss: 0.201566\tvalid_1's auc: 0.675025\tvalid_1's binary_logloss: 0.215855\n",
      "[671]\ttraining's auc: 0.782206\ttraining's binary_logloss: 0.201544\tvalid_1's auc: 0.674989\tvalid_1's binary_logloss: 0.21586\n",
      "[672]\ttraining's auc: 0.782306\ttraining's binary_logloss: 0.201525\tvalid_1's auc: 0.674976\tvalid_1's binary_logloss: 0.21586\n",
      "[673]\ttraining's auc: 0.782404\ttraining's binary_logloss: 0.201504\tvalid_1's auc: 0.675013\tvalid_1's binary_logloss: 0.215855\n",
      "[674]\ttraining's auc: 0.782467\ttraining's binary_logloss: 0.20149\tvalid_1's auc: 0.675007\tvalid_1's binary_logloss: 0.215856\n",
      "[675]\ttraining's auc: 0.782534\ttraining's binary_logloss: 0.20147\tvalid_1's auc: 0.675016\tvalid_1's binary_logloss: 0.215853\n",
      "[676]\ttraining's auc: 0.782646\ttraining's binary_logloss: 0.201451\tvalid_1's auc: 0.674982\tvalid_1's binary_logloss: 0.215859\n",
      "[677]\ttraining's auc: 0.782784\ttraining's binary_logloss: 0.201429\tvalid_1's auc: 0.675034\tvalid_1's binary_logloss: 0.215853\n",
      "[678]\ttraining's auc: 0.782854\ttraining's binary_logloss: 0.201416\tvalid_1's auc: 0.675025\tvalid_1's binary_logloss: 0.215854\n",
      "[679]\ttraining's auc: 0.782964\ttraining's binary_logloss: 0.201396\tvalid_1's auc: 0.675021\tvalid_1's binary_logloss: 0.215855\n",
      "[680]\ttraining's auc: 0.783049\ttraining's binary_logloss: 0.201376\tvalid_1's auc: 0.675006\tvalid_1's binary_logloss: 0.21586\n",
      "[681]\ttraining's auc: 0.783141\ttraining's binary_logloss: 0.201355\tvalid_1's auc: 0.674962\tvalid_1's binary_logloss: 0.215865\n",
      "[682]\ttraining's auc: 0.783277\ttraining's binary_logloss: 0.201333\tvalid_1's auc: 0.674934\tvalid_1's binary_logloss: 0.215867\n",
      "[683]\ttraining's auc: 0.783413\ttraining's binary_logloss: 0.201308\tvalid_1's auc: 0.674946\tvalid_1's binary_logloss: 0.215871\n",
      "[684]\ttraining's auc: 0.783518\ttraining's binary_logloss: 0.201286\tvalid_1's auc: 0.674929\tvalid_1's binary_logloss: 0.215871\n",
      "Early stopping, best iteration is:\n",
      "[584]\ttraining's auc: 0.773562\ttraining's binary_logloss: 0.203245\tvalid_1's auc: 0.674988\tvalid_1's binary_logloss: 0.215843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.8, learning_rate=0.015, max_depth=10,\n",
       "               min_child_samples=300, min_split_gain=0.1, n_estimators=2000,\n",
       "               num_leaves=51, objective='binary', reg_alpha=0.12,\n",
       "               reg_lambda=0.28, subsample=0.75, subsample_freq=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用LightGBM模型\n",
    "model = lgb.LGBMClassifier(\n",
    "    num_leaves=51,\n",
    "    max_depth=10,\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    learning_rate=0.015,\n",
    "    n_estimators=2000,\n",
    "    subsample=0.75,\n",
    "    subsample_freq=2,\n",
    "    reg_lambda=0.28,\n",
    "    reg_alpha=0.12,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_samples=300,\n",
    "    min_split_gain=0.1\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_metric='auc', \n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5oNFJNiuuWI1"
   },
   "source": [
    "### 测试集预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQX6Zqpitzua"
   },
   "outputs": [],
   "source": [
    "prob = model.predict_proba(test_data)\n",
    "df_test1['prob'] = pd.Series(prob[:,1])\n",
    "# df_test1.drop(['origin'], axis=1, inplace=True)\n",
    "df_test1.to_csv('prediction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "026nJmVREn10"
   },
   "source": [
    "- xgbboost 目前测试集最高得分0.6774169，prediction1.csv\n",
    "- lightgbm 目前测试集最高得分0.6827759，prediction2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWgY4b03rd18y+QHWbMziC",
   "collapsed_sections": [],
   "mount_file_id": "1BVsSQnq5YGCj9zTgUe8kJD8ldAsWO4AA",
   "name": "Tmall_Repeat_Buyers_boosting.ipynb",
   "provenance": [
    {
     "file_id": "12I0jTP81uXJo9u59HumxxukRzAV2Y34b",
     "timestamp": 1589730404670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
